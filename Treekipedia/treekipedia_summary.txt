Directory structure:
â””â”€â”€ Treekipedia/
    â”œâ”€â”€ README.md
    â”œâ”€â”€ components.json
    â”œâ”€â”€ index.js
    â”œâ”€â”€ next.config.ts
    â”œâ”€â”€ package.json
    â”œâ”€â”€ postcss.config.mjs
    â”œâ”€â”€ tailwind.config.ts
    â”œâ”€â”€ test.js
    â”œâ”€â”€ tsconfig.json
    â”œâ”€â”€ .agentkit.config.js
    â”œâ”€â”€ EAS/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â””â”€â”€ ResearchLogSchema.md
    â”œâ”€â”€ Ontology/
    â”‚   â”œâ”€â”€ schema.txt
    â”‚   â”œâ”€â”€ treekipedia1.ttl
    â”‚   â””â”€â”€ .DS_Store
    â”œâ”€â”€ Python Script/
    â”‚   â”œâ”€â”€ csv-rdf.py
    â”‚   â”œâ”€â”€ destroy-blazegraph-digitalocean.yml
    â”‚   â”œâ”€â”€ provision-blazegraph-digitalocean.yml
    â”‚   â””â”€â”€ .DS_Store
    â”œâ”€â”€ ai-agent/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â”œâ”€â”€ aiResearchService.js
    â”‚   â”œâ”€â”€ research.json
    â”‚   â”œâ”€â”€ sample.json
    â”‚   â”œâ”€â”€ server.js
    â”‚   â”œâ”€â”€ server.js.save
    â”‚   â”œâ”€â”€ server.js.save.1
    â”‚   â””â”€â”€ testAIResearch.js
    â”œâ”€â”€ backend/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â””â”€â”€ API_DOCS.md
    â”œâ”€â”€ backup/
    â”‚   â””â”€â”€ server.js
    â”œâ”€â”€ database/
    â”‚   â””â”€â”€ db_schema.sql
    â”œâ”€â”€ docs/
    â”‚   â””â”€â”€ README.md
    â”œâ”€â”€ public/
    â”œâ”€â”€ smart-contracts/
    â”‚   â”œâ”€â”€ README.md
    â”‚   â”œâ”€â”€ NFTree.sol
    â”‚   â”œâ”€â”€ abi.json
    â”‚   â”œâ”€â”€ createAttestation.js
    â”‚   â”œâ”€â”€ mintNFTree.js
    â”‚   â””â”€â”€ uploadToIPFS.js
    â””â”€â”€ src/
        â”œâ”€â”€ eslint.config.mjs
        â”œâ”€â”€ app/
        â”‚   â”œâ”€â”€ globals.css
        â”‚   â”œâ”€â”€ layout.tsx
        â”‚   â”œâ”€â”€ page.tsx
        â”‚   â”œâ”€â”€ providers.tsx
        â”‚   â””â”€â”€ species/
        â”‚       â”œâ”€â”€ page.tsx
        â”‚       â””â”€â”€ [id]/
        â”‚           â”œâ”€â”€ page.tsx
        â”‚           â””â”€â”€ nfts/
        â”‚               â””â”€â”€ page.tsx
        â”œâ”€â”€ components/
        â”‚   â”œâ”€â”€ navbar.tsx
        â”‚   â”œâ”€â”€ research-table.tsx
        â”‚   â”œâ”€â”€ search-form.tsx
        â”‚   â”œâ”€â”€ search-results.tsx
        â”‚   â””â”€â”€ ui/
        â”‚       â”œâ”€â”€ button.tsx
        â”‚       â”œâ”€â”€ input.tsx
        â”‚       â”œâ”€â”€ sonner.tsx
        â”‚       â””â”€â”€ table.tsx
        â”œâ”€â”€ context/
        â”‚   â””â”€â”€ research-context.tsx
        â””â”€â”€ lib/
            â”œâ”€â”€ api.ts
            â”œâ”€â”€ search-trees.ts
            â”œâ”€â”€ types.ts
            â””â”€â”€ utils.ts

================================================
File: README.md
================================================
# ðŸŒ³ Treekipedia

## About
Treekipedia is an open-source, AI-enhanced, Web3-integrated initiative to create a comprehensive, scalable, and decentralized database of tree-related knowledge. Our mission is to unify fragmented ecological datasetsâ€”spanning scientific, institutional, and Traditional Ecological Knowledge (TEK)â€”into a single, accessible, and interoperable resource serving researchers, conservationists, educators, and practitioners in agroforestry, reforestation, and related fields. By leveraging AI-driven autonomous agents, blockchain technology, and decentralized storage, Treekipedia addresses data fragmentation, enhances scalability, and ensures the integrity and transparency of global biodiversity and reforestation efforts.

## ðŸŽ¯ Project Objectives
- Create a unified taxonomy and species list as the foundation for an extensive tree knowledge graph, enhanced by AI-driven structuring and predictive analytics.
- Develop a structured ontology for organizing tree-related data, linking ecological attributes, climate resilience, and species interactions using a machine-readable format (RDF).
- Integrate data from multiple authoritative sources, including scientific archives, community inputs, and geospatial datasets, using AI and natural language processing (NLP).
- Provide an open, accessible, and decentralized platform for the global tree knowledge community, supported by blockchain-verified data provenance and NFT-based incentives.

## ðŸš€ Current Progress
- âœ… Hired a post-doctorate ecologist to lead ecological data integration.
- âœ… Developed a prototype taxonomic schema, now enhanced with AI-driven ontology structuring.
- âœ… Established data retrieval and filtering strategies using R Studio, integrated with AI Research Agents for automated data extraction and validation.
- âœ… Identified and compiled over 10+ source species databases (e.g., GBIF, iNaturalist, Wikidata, World Flora Online) and incorporated Traditional Ecological Knowledge (TEK).
- âœ… Set up GraphDB/BlazeGraph for decentralized data storage, with plans to expand to IPFS for permanence and accessibility.

## ðŸ“Š Data Sources
We integrate data from diverse authoritative sources to create a comprehensive ecological intelligence framework:
- GBIF (Global Biodiversity Information Facility)
- iNaturalist
- Wikidata
- World Flora Online (WFO)
- BGCI
- Traditional Ecological Knowledge (TEK) from grassroots and indigenous communities
- Geospatial datasets, multispectral satellite imagery, and sensor-based monitoring for real-time ecological insights
- And more...

## ðŸ› ï¸ Technical Stack
- **Data Processing:** R Studio, AI Research Agents with NLP and knowledge graph analysis
- **Data Storage:** GraphDB/BlazeGraph, decentralized storage via IPFS
- **Data Format:** RDF (Resource Description Framework) for machine-readable interoperability
- **Query Language:** SPARQL for querying the graph database
- **Database Type:** Graph Database, scalable for large-scale ecological datasets
- **Blockchain Integration:** Ethereum Attestation Service (EAS) for data authenticity, NFTrees (ERC-1155) and Contreebution NFTs (ERC-721) for incentives and validation

## ðŸ“ Key Features & Innovations
1. **AI-Driven Data Acquisition & Structuring**
   - AI Research Agents autonomously extract, standardize, and validate tree species data from peer-reviewed literature, research archives, and community inputs using NLP and knowledge graphs.
   - Predictive analytics with remote sensing (geospatial datasets, multispectral imaging) and reinforcement learning refine ecological modeling, forecasting tree survival, biodiversity impacts, and ecosystem resilience.
   - Agentic Peer Review Framework: AI-generated insights undergo expert and community-driven validation, ensuring credibility and reliability.

2. **Blockchain & Web3 Integration**
   - Decentralized storage on IPFS ensures data permanence and prevents centralization bottlenecks.
   - Ethereum Attestation Service (EAS) validates ecological data authenticity on-chain, reinforcing scientific credibility and immutability.
   - NFT-Based Incentive Structures:
     - **Species NFTs (NFTrees - ERC-1155)**: Dynamic, evolving representations of tree species knowledge that update with new data, serving as living knowledge artifacts.
     - **Contreebution NFTs (ERC-721)**: Awarded to contributors for research, peer reviews, or data validation, tracking individual contributions and incentivizing long-term engagement.
   - Interoperable APIs enable seamless integration with reforestation tools, biodiversity databases, and natural capital frameworks.

3. **Comprehensive Data Coverage**
   - Species information, geographic occurrences, habitat data, taxonomic details, and bioregional aptitude, enhanced by AI-driven synthesis.
   - Integration of TEK and scientific datasets for an equity-centered ecological intelligence framework.

4. **Data Management**
   - Large-scale, AI-powered data retrieval capabilities, filtered specifically for tree-related data.
   - Regular updates and maintenance, supported by decentralized governance and blockchain-verified provenance.
   - Geospatial and remote sensing integration for real-time monitoring of deforestation, afforestation, and biodiversity restoration.

## ðŸ—ºï¸ Roadmap & Development Trajectory
### Phase 1: Post-Hackathon & MVP Launch
- Resolve technical debt (e.g., frontend API issues, TaxonID integration, EAS schema implementation).
- Launch DeepTrees MVP for public testing (50-200 users, stretch goal: 1,000 users), monitoring stability and gathering feedback.
- Mint over 100 Contreebution NFTs and plan the â€˜Iconic Species Collectionâ€™ NFT auction (Genesis 100 trees).

### Phase 2: Refinement & Infrastructure Consolidation
- Optimize GraphDB/BlazeGraph and DeepTrees VM deployments for large datasets (>8GB occurrences).
- Implement data versioning and natural language SPARQL queries.
- Design a multi-step verification process for AI-generated data, including human review and community governance.

### Phase 3: Community Engagement & Governance Development
- Outreach to scientists, foresters, and ReFi organizations for partnerships.
- Establish Treekipedia Working Groups for ongoing validation and user contributions.
- Refine NFT-based incentives and launch the DeepTrees Iconic Species Collection, with community governance modeled on Wikipedia or DAOs.

### Phase 4: Scaling AI Research & Decentralized Validation
- Optimize AI retrieval and structuring algorithms for taxonomic and ecological data expansion.
- Build a peer-reviewed validation pipeline with weighted community governance and expanded EAS usage.
- Develop a data credibility scoring system for AI-generated research.

### Phase 5: Full-Scale Public Rollout & Silvi Integration
- Finalize Treekipedia APIs for broad use, connecting with Silvi for MRV and tree steward support.
- Launch a refined frontend with DeepTrees + Treekipedia integration, deploying advanced ecological models for carbon and biodiversity impact tracking.
- Scale to global partnerships with reforestation projects and biodiversity platforms, establishing Treekipedia as a global standard for ecological intelligence.

## ðŸ¤ Contributing
Weâ€™re building an open, decentralized community and welcome contributions! If youâ€™re interested in participating:
1. Contact @metafarmer on Telegram
2. Watch this space for upcoming contribution guidelines and NFT-based incentives (Contreebution NFTs).
3. Stay tuned for our open-source contributor process and governance structure.

## ðŸ“– Documentation
Detailed documentation about our data structure, ontology definitions, API interfaces, and contributing guidelines will be added as the project evolves. Visit our [Documentation Portal](https://docs.silvi.earth) for more information.

## ðŸ“§ Contact
For more information or to get involved, reach out to @metafarmer on Telegram or visit https://silvi.earth.

## ðŸ”„ Project Status
Treekipedia is an active, evolving project in development. The database, ontology, and AI-driven features will continuously expand as we integrate more data sources, refine models, and engage the global community.

## License
Copyright Â© 2025 Silvi. All rights reserved.



================================================
File: components.json
================================================
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "new-york",
  "rsc": true,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.ts",
    "css": "src/app/globals.css",
    "baseColor": "zinc",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  },
  "iconLibrary": "lucide"
}


================================================
File: index.js
================================================
// index.js
require('dotenv').config();
const express = require('express');
const morgan = require('morgan');
const { Pool } = require('pg');

const app = express();

// Middleware to parse JSON bodies
app.use(express.json());

// Use morgan for logging HTTP requests
app.use(morgan('combined'));

// Basic API key authentication middleware
app.use((req, res, next) => {
  const apiKey = req.headers['x-api-key'];
  if (!apiKey || apiKey !== process.env.API_KEY) {
    return res.status(401).json({ error: 'Unauthorized: API key missing or invalid' });
  }
  next();
});

// Set up PostgreSQL connection pool
const pool = new Pool({
  host: process.env.POSTGRES_HOST,
  port: process.env.POSTGRES_PORT,
  database: process.env.POSTGRES_DB,
  user: process.env.POSTGRES_USER,
  password: process.env.POSTGRES_PASSWORD,
});

// Endpoint for AI Data Submission: POST /research/drafts
// This inserts or updates a record in the ai_research table.
app.post('/research/drafts', async (req, res) => {
  try {
    const {
      taxon_id,
      general_description,
      native_adapted_habitats,
      stewardship_best_practices,
      planting_methods,
      ecological_function,
      agroforestry_use_cases,
      elevation_ranges,
      compatible_soil_types,
      conservation_status,
    } = req.body;

    if (!taxon_id) {
      return res.status(400).json({ error: 'Missing required field: taxon_id' });
    }

    // Insert new record; on conflict, update the record and increment revision
    const query = `
      INSERT INTO ai_research 
        (taxon_id, general_description, native_adapted_habitats, stewardship_best_practices, planting_methods, ecological_function, agroforestry_use_cases, elevation_ranges, compatible_soil_types, conservation_status, research_status)
      VALUES 
        ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 'unverified')
      ON CONFLICT (taxon_id) DO UPDATE SET 
        general_description = EXCLUDED.general_description,
        native_adapted_habitats = EXCLUDED.native_adapted_habitats,
        stewardship_best_practices = EXCLUDED.stewardship_best_practices,
        planting_methods = EXCLUDED.planting_methods,
        ecological_function = EXCLUDED.ecological_function,
        agroforestry_use_cases = EXCLUDED.agroforestry_use_cases,
        elevation_ranges = EXCLUDED.elevation_ranges,
        compatible_soil_types = EXCLUDED.compatible_soil_types,
        conservation_status = EXCLUDED.conservation_status,
        research_status = 'unverified',
        updated_at = CURRENT_TIMESTAMP,
        revision = ai_research.revision + 1;
    `;

    await pool.query(query, [
      taxon_id,
      general_description,
      native_adapted_habitats,
      stewardship_best_practices,
      planting_methods,
      ecological_function,
      agroforestry_use_cases,
      elevation_ranges,
      compatible_soil_types,
      conservation_status,
    ]);

    res.status(200).json({ message: 'Research draft submitted successfully.' });
  } catch (err) {
    console.error('Error in POST /research/drafts:', err);
    res.status(500).json({ error: 'Internal Server Error' });
  }
});

// Endpoint for Data Retrieval: GET /species/:id
// This fetches the AI research data for a given taxon_id.
app.get('/species/:id', async (req, res) => {
  try {
    const taxon_id = req.params.id;
    const query = `SELECT * FROM ai_research WHERE taxon_id = $1`;
    const result = await pool.query(query, [taxon_id]);

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Species not found.' });
    }

    res.status(200).json(result.rows[0]);
  } catch (err) {
    console.error('Error in GET /species/:id:', err);
    res.status(500).json({ error: 'Internal Server Error' });
  }
});

// Start the API server
const port = process.env.PORT || 3000;
app.listen(port, () => {
  console.log(`API Gateway listening on port ${port}`);
});



================================================
File: next.config.ts
================================================
import type { NextConfig } from "next";

const nextConfig: NextConfig = {
  /* config options here */
};

export default nextConfig;



================================================
File: package.json
================================================
{
  "name": "agentic-hackathon",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "next lint"
  },
  "dependencies": {
    "@coinbase/agentkit": "^0.1.2",
    "@ethereum-attestation-service/eas-sdk": "^2.7.0",
    "@coinbase/onchainkit": "^0.36.10",
    "@radix-ui/react-slot": "^1.1.1",
    "@tanstack/react-query": "^5.66.0",
    "@tanstack/react-query-devtools": "^5.66.0",
    "alchemy-sdk": "^3.5.2",
    "axios": "^1.7.9",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "cors": "^2.8.5",
    "dotenv": "^16.4.7",
    "ethers": "^6.13.5",
    "express": "^4.21.2",
    "form-data": "^4.0.1",
    "langchain": "^0.3.15",
    "lucide-react": "^0.474.0",
    "morgan": "^1.10.0",
    "next": "15.1.6",
    "next-themes": "^0.4.4",
    "openai": "^4.83.0",
    "pg": "^8.13.1",
    "react": "^19.0.0",
    "react-dom": "^19.0.0",
    "react-hot-toast": "^2.5.1",
    "sonner": "^1.7.4",
    "tailwind-merge": "^3.0.1",
    "tailwindcss-animate": "^1.0.7",
    "tw-neumorphism": "^0.2.0",
    "zustand": "^5.0.3"
  },
  "devDependencies": {
    "@eslint/eslintrc": "^3",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "15.1.6",
    "postcss": "^8",
    "tailwindcss": "^3.4.1",
    "typescript": "^5"
  },
  "description": "This is a Next.js project bootstrapped with create-next-app, combined with backend functionality for DeepTrees.",
  "main": "index.js",
  "author": "",
  "license": "ISC"
}




================================================
File: postcss.config.mjs
================================================
/** @type {import('postcss-load-config').Config} */
const config = {
  plugins: {
    tailwindcss: {},
  },
};

export default config;



================================================
File: tailwind.config.ts
================================================
import type { Config } from "tailwindcss";

export default {
    darkMode: ["class"],
    content: [
    "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
    "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
  ],
  theme: {
  	extend: {
  		colors: {
  			background: 'hsl(var(--background))',
  			foreground: 'hsl(var(--foreground))',
  			card: {
  				DEFAULT: 'hsl(var(--card))',
  				foreground: 'hsl(var(--card-foreground))'
  			},
  			popover: {
  				DEFAULT: 'hsl(var(--popover))',
  				foreground: 'hsl(var(--popover-foreground))'
  			},
  			primary: {
  				DEFAULT: 'hsl(var(--primary))',
  				foreground: 'hsl(var(--primary-foreground))'
  			},
  			secondary: {
  				DEFAULT: 'hsl(var(--secondary))',
  				foreground: 'hsl(var(--secondary-foreground))'
  			},
  			muted: {
  				DEFAULT: 'hsl(var(--muted))',
  				foreground: 'hsl(var(--muted-foreground))'
  			},
  			accent: {
  				DEFAULT: 'hsl(var(--accent))',
  				foreground: 'hsl(var(--accent-foreground))'
  			},
  			destructive: {
  				DEFAULT: 'hsl(var(--destructive))',
  				foreground: 'hsl(var(--destructive-foreground))'
  			},
  			border: 'hsl(var(--border))',
  			input: 'hsl(var(--input))',
  			ring: 'hsl(var(--ring))',
  			chart: {
  				'1': 'hsl(var(--chart-1))',
  				'2': 'hsl(var(--chart-2))',
  				'3': 'hsl(var(--chart-3))',
  				'4': 'hsl(var(--chart-4))',
  				'5': 'hsl(var(--chart-5))'
  			}
  		},
  		borderRadius: {
  			lg: 'var(--radius)',
  			md: 'calc(var(--radius) - 2px)',
  			sm: 'calc(var(--radius) - 4px)'
  		}
  	}
  },
  plugins: [require("tailwindcss-animate")],
} satisfies Config;



================================================
File: test.js
================================================
// Load environment variables from .env file
require('dotenv').config();
console.log("Environment variables loaded:");
console.log(process.env);



================================================
File: tsconfig.json
================================================
{
  "compilerOptions": {
    "target": "ES2017",
    "lib": ["dom", "dom.iterable", "esnext"],
    "allowJs": true,
    "skipLibCheck": true,
    "strict": true,
    "noEmit": true,
    "esModuleInterop": true,
    "module": "esnext",
    "moduleResolution": "bundler",
    "resolveJsonModule": true,
    "isolatedModules": true,
    "jsx": "preserve",
    "incremental": true,
    "plugins": [
      {
        "name": "next"
      }
    ],
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
  "exclude": ["node_modules"]
}



================================================
File: .agentkit.config.js
================================================
module.exports = {
  openaiApiKey: process.env.OPENAI_API_KEY,
  cdp: {
    apiKey: process.env.CDP_API_KEY,
    apiSecret: process.env.CDP_API_SECRET,
  },
  wallet: {
    privateKey: process.env.AGENTKIT_WALLET_PRIVATE_KEY,
  },
  blockchain: {
    rpcUrl: process.env.BASE_L2_RPC_URL,
    network: 'base-l2-testnet', // adjust as needed based on your provider
  },
  // Add any other AgentKit-specific settings here
};



================================================
File: EAS/README.md
================================================
# Ethereum Attestation Service (EAS) Integration

This folder will contain the code and documentation for integrating the Ethereum Attestation Service (EAS) into the DeepTrees project.

## Overview

The EAS integration will handle:
- **On-Chain Attestations:** Validating AI-researched species data on-chain.
- **NFTree Minting:** Linking attested research data to NFTree tokens.
- **Smart Contract Interactions:** Managing low-cost transactions on Base L2.
- **Workflow Integration:** Connecting the EAS processes with our AI agent and PostgreSQL storage.

## Next Steps

- Develop smart contracts (ERC-721) for dynamic NFTree minting.
- Implement API endpoints to trigger EAS attestations.
- Integrate on-chain verification into the DeepTrees backend.
- Document deployment procedures and testing on Base L2.

This is an initial placeholder. Future commits will add detailed implementation and configuration scripts.



================================================
File: EAS/ResearchLogSchema.md
================================================
# ResearchLogSchema

https://base-sepolia.easscan.org/schema/view/0x879ed82d38bd26318e55e4803c5699f3191e3e9ca2ffbf75d0cdf16524e4d9d3

# Using EAS SDK
```
import  { EAS, SchemaEncoder }  from "@ethereum-attestation-service/eas-sdk";
const easContractAddress = "0x4200000000000000000000000000000000000021";
const schemaUID = "0x879ed82d38bd26318e55e4803c5699f3191e3e9ca2ffbf75d0cdf16524e4d9d3";
const eas = new EAS(easContractAddress);
// Signer must be an ethers-like signer.
await eas.connect(signer);
// Initialize SchemaEncoder with the schema string
const schemaEncoder = new SchemaEncoder("uint256 researchLogID,address triggerWallet,string scientificName,string speciesUID,string[] speciesURL,string llmModel,string ipfsCID,uint16 numberInsights,uint16 numberCitations");
const encodedData = schemaEncoder.encodeData([
	{ name: "researchLogID", value: "0", type: "uint256" }
	{ name: "triggerWallet", value: "0x0000000000000000000000000000000000000000", type: "address" }
	{ name: "scientificName", value: "", type: "string" }
	{ name: "speciesUID", value: "", type: "string" }
	{ name: "speciesURL", value: [], type: "string[]" }
	{ name: "llmModel", value: "", type: "string" }
	{ name: "ipfsCID", value: "", type: "string" }
	{ name: "numberInsights", value: "0", type: "uint16" }
	{ name: "numberCitations", value: "0", type: "uint16" }
]);
const tx = await eas.attest({
	schema: schemaUID,
	data: {
		recipient: "0x0000000000000000000000000000000000000000",
		expirationTime: 0,
		revocable: false, // Be aware that if your schema is not revocable, this MUST be false
		data: encodedData,
	},
});
const newAttestationUID = await tx.wait();
console.log("New attestation UID:", newAttestationUID);



================================================
File: Ontology/schema.txt
================================================
family
genus
specific_epithet
species
subspecies
common_name
accepted_scientific_name
synonyms
ecoregions (option set)
biomes (option set)
bioregions (option set)
common_countries (option set)
countries_introduced (option set)
countries_invasive (option set)
countries_native (option set)
general_description
habitat (option set)
forest_type (option set)
wetland_type (option set)
urban_setting (option set)
ecological_function (option set)
climate_change_vulnerability (option set)
elevation_ranges
compatible_soil_types (option set)
associated_species
native_adapted_habitats (option set)
agroforestry_use_cases (option set)
successional_stage (option set)
tolerances (option set)
forest_layers (option set)
growth_form (option set)
leaf_type (option set)
deciduous_evergreen (option set)
flower_color (option set)
fruit_type (option set)
bark_characteristics (option set)
maximum_height
maximum_diameter
lifespan
maximum_tree_age
allometric_models
allometric_curve
conservation_status (option set)
national_conservation_status (option set)
verification_status (option set)
threats (option set)
timber_value
non_timber_products (option set)
cultural_significance (option set)
cultivars
nutritional_caloric_value
cultivation_details
stewardship_best_practices
planting_recipes
pruning_maintenance
disease_pest_management (option set)
fire_management (option set)
references
data_sources
total_occurrences
associated_media
default_image
ipfs_cid
last_updated_date


================================================
File: Ontology/treekipedia1.ttl
================================================
@prefix : <http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia/> .
@prefix owl: <http://www.w3.org/2002/07/owl#> .
@prefix rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#> .
@prefix xml: <http://www.w3.org/XML/1998/namespace> .
@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .
@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .
@base <http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia/> .

<http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia> rdf:type owl:Ontology .

#################################################################
#    Object Properties
#################################################################

###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#foundInHabitat
:foundInHabitat rdf:type owl:ObjectProperty ;
                rdfs:domain :TreeSpecies ;
                rdfs:range :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#hasAllometricData
:hasAllometricData rdf:type owl:ObjectProperty ;
                   rdfs:domain :TreeSpecies ;
                   rdfs:range :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#hasConservationStatus
:hasConservationStatus rdf:type owl:ObjectProperty ;
                       rdfs:domain :TreeSpecies ;
                       rdfs:range :EcologicalData .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#hasEcoregion
:hasEcoregion rdf:type owl:ObjectProperty ;
              rdfs:domain :EcologicalData ;
              rdfs:range :EcologicalData .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#hasIssues
:hasIssues rdf:type owl:ObjectProperty ;
           rdfs:domain :DataQualityAssessment ;
           rdfs:range :DataQualityAssessment .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#hasMedia
:hasMedia rdf:type owl:ObjectProperty ;
          rdfs:domain :GeneralKnowledge ;
          rdfs:range :AssociatedMedia .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#hasReproductiveCondition
:hasReproductiveCondition rdf:type owl:ObjectProperty ;
                          rdfs:domain :TreeSpecies ;
                          rdfs:range :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#hasSubspecies
:hasSubspecies rdf:type owl:ObjectProperty ;
               rdfs:domain :TreeSpecies ;
               rdfs:range :Subspecies .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#identifiedBy
:identifiedBy rdf:type owl:ObjectProperty ;
              rdfs:domain :Occurrence ;
              rdfs:range :IdentifiedBy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#locatedInCountry
:locatedInCountry rdf:type owl:ObjectProperty ;
                  rdfs:domain :Occurrence ;
                  rdfs:range :Country ,
                             :Locality .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#locatedInLocality
:locatedInLocality rdf:type owl:ObjectProperty ;
                   rdfs:domain :Occurrence ;
                   rdfs:range :Locality .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#locatedIncontinent
:locatedIncontinent rdf:type owl:ObjectProperty ;
                    rdfs:domain :Occurrence ;
                    rdfs:range :Continent .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#recordedBy
:recordedBy rdf:type owl:ObjectProperty ;
            rdfs:domain :Occurrence ;
            rdfs:range :RecordedBy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#verifiedBy
:verifiedBy rdf:type owl:ObjectProperty ;
            rdfs:domain :DataQualityAssessment ;
            rdfs:range :VerifiedBy .


#################################################################
#    Data properties
#################################################################

###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#SpeciesID
:SpeciesID rdf:type owl:DatatypeProperty ;
           rdfs:domain :TreeSpecies ;
           rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#acceptedScientificName
:acceptedScientificName rdf:type owl:DatatypeProperty ;
                        rdfs:domain :Taxonomy ;
                        rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#allometricData
:allometricData rdf:type owl:DatatypeProperty ;
                rdfs:domain :GeneralKnowledge ;
                rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#bestPracticesNotes
:bestPracticesNotes rdf:type owl:DatatypeProperty ;
                    rdfs:domain :GeneralKnowledge ;
                    rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#commonName
:commonName rdf:type owl:DatatypeProperty ;
            rdfs:domain :Taxonomy ;
            rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#conservationStatus
:conservationStatus rdf:type owl:DatatypeProperty ;
                    rdfs:domain :EcologicalData ;
                    rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#continentName
:continentName rdf:type owl:DatatypeProperty ;
               rdfs:domain :Occurrence ;
               rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#countryName
:countryName rdf:type owl:DatatypeProperty ;
             rdfs:domain :Occurrence ;
             rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#description
:description rdf:type owl:DatatypeProperty ;
             rdfs:domain :GeneralKnowledge ;
             rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#ecologicalFunction
:ecologicalFunction rdf:type owl:DatatypeProperty ;
                    rdfs:domain :EcologicalData ;
                    rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#ecoregionName
:ecoregionName rdf:type owl:DatatypeProperty ;
               rdfs:domain :EcologicalData ;
               rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#elevation
:elevation rdf:type owl:DatatypeProperty ;
           rdfs:domain :EcologicalData ;
           rdfs:range xsd:decimal .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#familyName
:familyName rdf:type owl:DatatypeProperty ;
            rdfs:domain :Taxonomy ;
            rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#genusName
:genusName rdf:type owl:DatatypeProperty ;
           rdfs:domain :Taxonomy ;
           rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#geodeticDatum
:geodeticDatum rdf:type owl:DatatypeProperty ;
               rdfs:domain :Occurrence ;
               rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#habitatDescription
:habitatDescription rdf:type owl:DatatypeProperty ;
                    rdfs:domain :GeneralKnowledge ;
                    rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#habitatType
:habitatType rdf:type owl:DatatypeProperty ;
             rdfs:domain :EcologicalData ;
             rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#identificationDate
:identificationDate rdf:type owl:DatatypeProperty ;
                    rdfs:domain :DataQualityAssessment ;
                    rdfs:range xsd:dateTime .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#identifiedBy
:identifiedBy rdf:type owl:DatatypeProperty ;
              rdfs:domain :Occurrence ;
              rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#issuesNotes
:issuesNotes rdf:type owl:DatatypeProperty ;
             rdfs:domain :GeneralKnowledge ;
             rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#latitude
:latitude rdf:type owl:DatatypeProperty ;
          rdfs:domain :Occurrence ;
          rdfs:range xsd:decimal .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#localityName
:localityName rdf:type owl:DatatypeProperty ;
              rdfs:domain :Occurrence ;
              rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#longitude
:longitude rdf:type owl:DatatypeProperty ;
           rdfs:domain :Occurrence ;
           rdfs:range xsd:decimal .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#mediaLinks
:mediaLinks rdf:type owl:DatatypeProperty ;
            rdfs:domain :GeneralKnowledge ;
            rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#mediaReferences
:mediaReferences rdf:type owl:DatatypeProperty ;
                 rdfs:domain :DataQualityAssessment ;
                 rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#occurenceStatus
:occurenceStatus rdf:type owl:DatatypeProperty ;
                 rdfs:domain :Occurrence ;
                 rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#protocolUsed
:protocolUsed rdf:type owl:DatatypeProperty ;
              rdfs:domain :GeneralKnowledge ;
              rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#qualityIssues
:qualityIssues rdf:type owl:DatatypeProperty ;
               rdfs:domain :DataQualityAssessment ;
               rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#recordedBy
:recordedBy rdf:type owl:DatatypeProperty ;
            rdfs:domain :Occurrence ;
            rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#recordedDay
:recordedDay rdf:type owl:DatatypeProperty ;
             rdfs:domain :Occurrence ;
             rdfs:range xsd:integer .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#recordedMonth
:recordedMonth rdf:type owl:DatatypeProperty ;
               rdfs:domain :Occurrence ;
               rdfs:range xsd:integer .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#recordedYear
:recordedYear rdf:type owl:DatatypeProperty ;
              rdfs:domain :Occurrence ;
              rdfs:range xsd:integer .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#reproductiveCondition
:reproductiveCondition rdf:type owl:DatatypeProperty ;
                       rdfs:domain :Taxonomy ;
                       rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#sex
:sex rdf:type owl:DatatypeProperty ;
     rdfs:domain :Taxonomy ;
     rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#speciesGuess
:speciesGuess rdf:type owl:DatatypeProperty ;
              rdfs:domain :Taxonomy ;
              rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#speciesName
:speciesName rdf:type owl:DatatypeProperty ;
             rdfs:domain :Taxonomy ;
             rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#specificEpithet
:specificEpithet rdf:type owl:DatatypeProperty ;
                 rdfs:domain :Taxonomy ;
                 rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#subSpeciesName
:subSpeciesName rdf:type owl:DatatypeProperty ;
                rdfs:domain :Taxonomy ;
                rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#taxonID
:taxonID rdf:type owl:DatatypeProperty ;
         rdfs:domain :Taxonomy ;
         rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#taxonRank
:taxonRank rdf:type owl:DatatypeProperty ;
           rdfs:domain :Taxonomy ;
           rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#taxonomicStatus
:taxonomicStatus rdf:type owl:DatatypeProperty ;
                 rdfs:domain :Taxonomy ;
                 rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#treeAge
:treeAge rdf:type owl:DatatypeProperty ;
         rdfs:domain :Occurrence ;
         rdfs:range xsd:integer .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#verificationDate
:verificationDate rdf:type owl:DatatypeProperty ;
                  rdfs:domain :DataQualityAssessment ;
                  rdfs:range xsd:dateTime .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#verificationStatus
:verificationStatus rdf:type owl:DatatypeProperty ;
                    rdfs:domain :DataQualityAssessment ;
                    rdfs:range xsd:string .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#verifiedBy
:verifiedBy rdf:type owl:DatatypeProperty ;
            rdfs:domain :DataQualityAssessment ;
            rdfs:range xsd:string .


#################################################################
#    Classes
#################################################################

###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#AcceptedScientificName
:AcceptedScientificName rdf:type owl:Class ;
                        rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#AllometricData
:AllometricData rdf:type owl:Class ;
                rdfs:subClassOf :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#AssociatedMedia
:AssociatedMedia rdf:type owl:Class ;
                 rdfs:subClassOf :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#BestPractise
:BestPractise rdf:type owl:Class ;
              rdfs:subClassOf :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#CommonName
:CommonName rdf:type owl:Class ;
            rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#ConservationStatus
:ConservationStatus rdf:type owl:Class ;
                    rdfs:subClassOf :EcologicalData .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Continent
:Continent rdf:type owl:Class ;
           rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Country
:Country rdf:type owl:Class ;
         rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#DataQualityAssessment
:DataQualityAssessment rdf:type owl:Class .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Day
:Day rdf:type owl:Class ;
     rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#DecimalLatitude
:DecimalLatitude rdf:type owl:Class ;
                 rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#DecimalLongitude
:DecimalLongitude rdf:type owl:Class ;
                  rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Description
:Description rdf:type owl:Class ;
             rdfs:subClassOf :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#EcologicalData
:EcologicalData rdf:type owl:Class .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#EcologicalFunction
:EcologicalFunction rdf:type owl:Class ;
                    rdfs:subClassOf :EcologicalData .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Ecoregion
:Ecoregion rdf:type owl:Class ;
           rdfs:subClassOf :EcologicalData .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#ElevationinMeters
:ElevationinMeters rdf:type owl:Class ;
                   rdfs:subClassOf :EcologicalData .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Family
:Family rdf:type owl:Class ;
        rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#GeneralKnowledge
:GeneralKnowledge rdf:type owl:Class .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Genus
:Genus rdf:type owl:Class ;
       rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#GeodeticDatum
:GeodeticDatum rdf:type owl:Class ;
               rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Habitat
:Habitat rdf:type owl:Class ;
         rdfs:subClassOf :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#IdentificationDate
:IdentificationDate rdf:type owl:Class ;
                    rdfs:subClassOf :DataQualityAssessment .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#IdentificationVerificationStatus
:IdentificationVerificationStatus rdf:type owl:Class ;
                                  rdfs:subClassOf :DataQualityAssessment .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#IdentifiedBy
:IdentifiedBy rdf:type owl:Class ;
              rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Issues
:Issues rdf:type owl:Class ;
        rdfs:subClassOf :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Locality
:Locality rdf:type owl:Class ;
          rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Month
:Month rdf:type owl:Class ;
       rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Occurrence
:Occurrence rdf:type owl:Class .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#OccurrenceStatus
:OccurrenceStatus rdf:type owl:Class ;
                  rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Protocol
:Protocol rdf:type owl:Class ;
          rdfs:subClassOf :GeneralKnowledge .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#RecordedBy
:RecordedBy rdf:type owl:Class ;
            rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#ReproductiveCondition
:ReproductiveCondition rdf:type owl:Class ;
                       rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Sex
:Sex rdf:type owl:Class ;
     rdfs:subClassOf :EcologicalData .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Species
:Species rdf:type owl:Class ;
         rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#SpeciesGenus
:SpeciesGenus rdf:type owl:Class ;
              rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#SpeciesID
:SpeciesID rdf:type owl:Class ;
           rdfs:subClassOf :TreeSpecies .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#SpecificEpithet
:SpecificEpithet rdf:type owl:Class ;
                 rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Subspecies
:Subspecies rdf:type owl:Class ;
            rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#TaxonID
:TaxonID rdf:type owl:Class ;
         rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#TaxonRank
:TaxonRank rdf:type owl:Class ;
           rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#TaxonomicStatus
:TaxonomicStatus rdf:type owl:Class ;
                 rdfs:subClassOf :Taxonomy .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Taxonomy
:Taxonomy rdf:type owl:Class .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#TreeAge
:TreeAge rdf:type owl:Class ;
         rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#TreeSpecies
:TreeSpecies rdf:type owl:Class .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#VerificationDate
:VerificationDate rdf:type owl:Class ;
                  rdfs:subClassOf :DataQualityAssessment .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#VerifiedBy
:VerifiedBy rdf:type owl:Class ;
            rdfs:subClassOf :DataQualityAssessment .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#Year
:Year rdf:type owl:Class ;
      rdfs:subClassOf :Occurrence .


###  http://www.semanticweb.org/jeremicarose/ontologies/2024/8/treekipedia#sex
:sex rdf:type owl:Class ;
     rdfs:subClassOf :Taxonomy .


###  Generated by the OWL API (version 4.5.29.2024-05-13T12:11:03Z) https://github.com/owlcs/owlapi



================================================
File: Ontology/.DS_Store
================================================
[Non-text file]


================================================
File: Python Script/csv-rdf.py
================================================
import csv
from rdflib import Graph, Literal, Namespace, URIRef
from rdflib.namespace import RDF, RDFS, XSD

def csv_to_rdf(csv_file, rdf_file, base_uri):
    # Create a new RDF graph
    g = Graph()

    # Define a custom namespace for our data
    DATA = Namespace(base_uri)

    # Read the CSV file
    with open(csv_file, 'r') as file:
        csv_reader = csv.DictReader(file)
        
        # Get the field names (column headers)
        fields = csv_reader.fieldnames

        # Process each row in the CSV
        for row_num, row in enumerate(csv_reader):
            # Create a unique subject for this row
            subject = URIRef(f"{base_uri}row/{row_num}")

            # Add a type for the row
            g.add((subject, RDF.type, DATA.Row))

            # Add triples for each column
            for field in fields:
                predicate = DATA[field.replace(' ', '_').lower()]
                obj = Literal(row[field])
                g.add((subject, predicate, obj))

    # Serialize the graph to a file
    g.serialize(destination=rdf_file, format='turtle')

# Example usage
csv_file = 'input.csv'
rdf_file = 'output.ttl'
base_uri = 'http://example.org/data/'

csv_to_rdf(csv_file, rdf_file, base_uri)
print(f"RDF data has been written to {rdf_file}")


================================================
File: Python Script/destroy-blazegraph-digitalocean.yml
================================================
- name: Destroy DigitalOcean Droplet with Blazegraph
  hosts: localhost
  connection: local
  gather_facts: no
  vars:
    droplet_name: blazegraph-droplet

  tasks:
    - name: Get the list of droplets
      community.digitalocean.digital_ocean_droplet_info:
        api_token: "{{ lookup('env', 'DO_API_TOKEN') }}"
      register: droplets_info

    - name: Find the droplet to destroy
      set_fact:
        droplet_id: "{{ item.id }}"
      loop: "{{ droplets_info.data|selectattr('name', 'equalto', droplet_name)|list }}"
      when: item.name == droplet_name

    - name: Destroy the droplet
      community.digitalocean.digital_ocean_droplet:
        state: absent
        api_token: "{{ lookup('env', 'DO_API_TOKEN') }}"
        id: "{{ droplet_id }}"
      when: droplet_id is defined




================================================
File: Python Script/provision-blazegraph-digitalocean.yml
================================================
---
- name: Provision and Configure DigitalOcean Droplet with Blazegraph
  hosts: localhost
  connection: local
  gather_facts: no
  vars:
    droplet_name: blazegraph-droplet
    region: nyc3
    size: s-1vcpu-1gb
    image: ubuntu-20-04-x64
  tasks:
    - name: Create a new DigitalOcean droplet
      community.digitalocean.digital_ocean_droplet:
        state: present
        api_token: "{{ lookup('env', 'DO_API_TOKEN') }}"
        name: "{{ droplet_name }}"
        region: "{{ region }}"
        size: "{{ size }}"
        image: "{{ image }}"
        ssh_keys: ["{{ lookup('env', 'DO_SSH_KEY_ID') }}"]
      register: droplet

    - name: Output Droplet Information
      debug:
        msg:
          - "Droplet Name: {{ droplet.data.droplet.name }}"
          - "Droplet IP: {{ droplet.data.droplet.networks.v4[0].ip_address }}"
          - "Droplet Region: {{ droplet.data.droplet.region.name }}"
          - "Droplet Status: {{ droplet.data.droplet.status }}"

    - name: Wait for SSH to be ready
      wait_for:
        host: "{{ droplet.data.droplet.networks.v4[0].ip_address }}"
        port: 22
        timeout: 300
        state: started

    - name: Add droplet IP to dynamic inventory
      add_host:
        name: "{{ droplet.data.droplet.networks.v4[0].ip_address }}"
        groups: provisioned_droplets
        ansible_user: root
        ansible_ssh_private_key_file: ~/.ansible/digitalocean.pem
        ansible_ssh_common_args: "-o StrictHostKeyChecking=no"

- name: Configure Droplet and Set Up Blazegraph
  hosts: provisioned_droplets
  become: yes
  vars:
    blazegraph_url: https://repo1.maven.org/maven2/com/blazegraph/blazegraph-jar/2.1.5/blazegraph-jar-2.1.5.jar
    blazegraph_dest: /opt/blazegraph.jar
  tasks:
    # - name: Wait for apt lock to be released
    #   command: |
    #     bash -c 'while fuser /var/lib/dpkg/lock-frontend /var/lib/apt/lists/lock >/dev/null 2>&1; do sleep 1; done'

    - name: Kill process holding apt lock (if necessary)
      shell: |
        kill -9 $(lsof -t /var/lib/dpkg/lock-frontend /var/lib/apt/lists/lock) 2>/dev/null || true

    - name: Update and upgrade apt packages
      apt:
        update_cache: yes
        upgrade: dist

    - name: Install Java (Blazegraph dependency)
      apt:
        name: openjdk-8-jdk
        state: present

    - name: Download Blazegraph
      get_url:
        url: "{{ blazegraph_url }}"
        dest: "{{ blazegraph_dest }}"
        mode: '0755'

    - name: Create a systemd service for Blazegraph
      copy:
        dest: /etc/systemd/system/blazegraph.service
        content: |
          [Unit]
          Description=Blazegraph Database
          After=network.target

          [Service]
          User=root
          ExecStart=/usr/bin/java -server -jar {{ blazegraph_dest }}
          Restart=always

          [Install]
          WantedBy=multi-user.target

    - name: Reload systemd and start Blazegraph
      systemd:
        daemon_reload: yes
        name: blazegraph
        state: started
        enabled: yes
  


================================================
File: Python Script/.DS_Store
================================================
[Non-text file]


================================================
File: ai-agent/README.md
================================================
# AI Agent



================================================
File: ai-agent/aiResearchService.js
================================================
// Load environment variables from the .env file located in the repository root
require('dotenv').config({ path: '../.env' });

// Import required modules
const axios = require('axios');
const agentkit = require('@coinbase/agentkit');

// Retrieve API keys from environment variables
const PERPLEXITY_API_KEY = process.env.PERPLEXITY_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

// --- Function: queryPerplexity ---
// Constructs a query using the scientificName and commonNames, then calls the Perplexity API
// to retrieve unstructured search results that include: general description, native/adapted habitats,
// stewardship best practices, planting methods, ecological function, agroforestry use-cases,
// elevation ranges, compatible soil types, and conservation status.
async function queryPerplexity(scientificName, commonNames) {
  const queryMessage = `Research tree species: ${scientificName}. Gather detailed information on:
- General description,
- Native or adapted habitats and regions,
- Stewardship best practices,
- Planting methods,
- Ecological function,
- Agroforestry use-cases,
- Elevation ranges,
- Compatible soil types,
- Conservation status.
Common names: ${Array.isArray(commonNames) ? commonNames.join(', ') : commonNames}.`;
  
  // Use the Perplexity API endpoint as per their documentation.
  const url = 'https://api.perplexity.ai/chat/completions';
  const headers = {
    'Content-Type': 'application/json',
    'Accept': 'application/json',
    'Authorization': `Bearer ${PERPLEXITY_API_KEY}`
  };
  const payload = {
    model: 'sonar-pro',
    messages: [
      { role: 'system', content: 'Be precise and concise.' },
      { role: 'user', content: queryMessage }
    ]
    // For structured outputs, you could include a "response_format" parameter if enabled on your account.
  };

  try {
    console.log('Querying Perplexity API with message:', queryMessage);
    const response = await axios.post(url, payload, { headers });
    // Extract the message content from the first choice.
    const unstructuredData = response.data.choices[0].message.content.trim();
    console.log('Received unstructured data from Perplexity:', unstructuredData);
    return unstructuredData;
  } catch (error) {
    console.error('Error querying Perplexity API:', error.response ? error.response.data : error.message);
    throw error;
  }
}

// --- Function: refineWithChatGPT ---
// Uses the ChatGPT 4o API to refine the unstructured data into structured JSON output.
// The output will conform to the DeepTrees PostgreSQL schema.
async function refineWithChatGPT(unstructuredData, scientificName, commonNames) {
  const prompt = `
You are an expert botanist and data analyst.
Using the following unstructured search results:
"${unstructuredData}"
Provide a detailed research summary for the tree species with scientific name "${scientificName}" and common names "${Array.isArray(commonNames) ? commonNames.join(', ') : commonNames}".
Output the data in the following JSON format (do not include any extra text):

{
  "general_description": "A brief description of the species.",
  "native_adapted_habitats": "Regions and climates.",
  "stewardship_best_practices": "Guidelines for care.",
  "planting_methods": "Propagation methods.",
  "ecological_function": "Ecosystem roles.",
  "agroforestry_use_cases": "Uses in agroforestry.",
  "elevation_ranges": "Suitable elevation ranges.",
  "compatible_soil_types": "Preferred soil conditions.",
  "conservation_status": "Conservation status."
}
  `;
  const url = 'https://api.openai.com/v1/chat/completions';
  const headers = {
    'Content-Type': 'application/json',
    'Authorization': `Bearer ${OPENAI_API_KEY}`
  };
  const payload = {
    model: 'gpt-4',
    messages: [
      { role: 'system', content: 'You are an expert botanist.' },
      { role: 'user', content: prompt }
    ],
    temperature: 0.7,
    max_tokens: 500
  };

  try {
    console.log('Calling ChatGPT 4o API to refine data...');
    const response = await axios.post(url, payload, { headers });
    const chatOutput = response.data.choices[0].message.content.trim();
    console.log('Raw output from ChatGPT 4o:', chatOutput);

    let structuredData;
    try {
      structuredData = JSON.parse(chatOutput);
    } catch (parseError) {
      console.error('Error parsing ChatGPT output as JSON:', parseError);
      structuredData = { general_description: chatOutput };
    }
    return structuredData;
  } catch (error) {
    console.error('Error calling ChatGPT 4o API:', error.response ? error.response.data : error.message);
    throw error;
  }
}

// --- Function: performAIResearch ---
// Orchestrates the two-step process: first calls Perplexity API, then refines the data using ChatGPT 4o.
// Accepts: taxonID, scientificName, commonNames, researcherWallet.
async function performAIResearch(taxonID, scientificName, commonNames, researcherWallet) {
  try {
    // Use AgentKit for any onchain pre-checks or logging (placeholder for now)
    if (typeof agentkit.dummyFunction === 'function') {
      agentkit.dummyFunction();
    } else {
      console.warn("AgentKit dummy function is not available.");
    }

    // Step 1: Retrieve unstructured data from Perplexity API.
    const unstructuredData = await queryPerplexity(scientificName, commonNames);

    // Step 2: Refine the unstructured data using ChatGPT 4o API.
    const structuredJSON = await refineWithChatGPT(unstructuredData, scientificName, commonNames);

    // Return the combined result with taxon_id.
    // (The researcherWallet is used in later steps for onchain actions and is not stored per the current schema.)
    return {
      taxon_id: taxonID,
      ...structuredJSON
    };
  } catch (error) {
    console.error('Error during AI research process:', error);
    throw error;
  }
}

// Export the performAIResearch function so it can be used in your API endpoints.
module.exports = { performAIResearch };



================================================
File: ai-agent/research.json
================================================
{
  "taxon_id": "Acacia_dealbata_test",
  "general_description": "Sample description.",
  "native_adapted_habitats": "Sample habitats.",
  "stewardship_best_practices": "Sample best practices.",
  "planting_methods": "Sample planting methods.",
  "ecological_function": "Sample ecological function.",
  "agroforestry_use_cases": "Sample agroforestry uses.",
  "elevation_ranges": "350-1000m",
  "compatible_soil_types": "Loam",
  "conservation_status": "Least Concern"
}



================================================
File: ai-agent/sample.json
================================================
{"test": "data"}



================================================
File: ai-agent/server.js
================================================
// ai-agent/server.js

// Global error handlers to catch unhandled errors
process.on('uncaughtException', err => {
  console.error('Uncaught Exception:', err);
});
process.on('unhandledRejection', err => {
  console.error('Unhandled Rejection:', err);
});

// Load environment variables from the repository root .env file
require('dotenv').config({ path: '../.env' });
console.log("DB_HOST is:", process.env.DB_HOST);
console.log("LIGHTHOUSE_API_KEY is:", process.env.LIGHTHOUSE_API_KEY);
console.log("BASE_L2_RPC_URL is:", process.env.BASE_L2_RPC_URL);

// Import required modules
const express = require('express');
const cors = require('cors');
const axios = require('axios');
const FormData = require('form-data');
const { Pool } = require('pg');
const { createAttestation } = require('../smart-contracts/createAttestation');
const { uploadResearchToIPFS } = require('../smart-contracts/uploadToIPFS');
const { mintNFTree } = require('../smart-contracts/mintNFTree');
const path = require('path');

// Import the AI research service (Perplexity + ChatGPT 4o flow)
const { performAIResearch } = require('./aiResearchService');

// Create an Express application
const app = express();
app.use(cors());
app.use(express.json());

// Set up PostgreSQL connection pool using the DB_ variables from .env
const pool = new Pool({
  host: process.env.DB_HOST,
  port: process.env.DB_PORT,
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD
});

// --- Function: storeResearchInDB ---
// Inserts the research data into the ai_research table.
async function storeResearchInDB(researchData, ipfsCid, researcherWallet) {
  const query = `
    INSERT INTO ai_research (
      taxon_id,
      general_description,
      native_adapted_habitats,
      stewardship_best_practices,
      planting_methods,
      ecological_function,
      agroforestry_use_cases,
      elevation_ranges,
      compatible_soil_types,
      conservation_status,
      research_status,
      ipfs_cid,
      researcher_wallet,
      revision,
      revision_history,
      created_at,
      updated_at
    ) VALUES (
      $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 'unverified', $11, $12, 1, '[]', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
    )
    ON CONFLICT (taxon_id) DO UPDATE SET
      general_description = EXCLUDED.general_description,
      native_adapted_habitats = EXCLUDED.native_adapted_habitats,
      stewardship_best_practices = EXCLUDED.stewardship_best_practices,
      planting_methods = EXCLUDED.planting_methods,
      ecological_function = EXCLUDED.ecological_function,
      agroforestry_use_cases = EXCLUDED.agroforestry_use_cases,
      elevation_ranges = EXCLUDED.elevation_ranges,
      compatible_soil_types = EXCLUDED.compatible_soil_types,
      conservation_status = EXCLUDED.conservation_status,
      research_status = 'unverified',
      ipfs_cid = EXCLUDED.ipfs_cid,
      researcher_wallet = EXCLUDED.researcher_wallet,
      updated_at = CURRENT_TIMESTAMP;
  `;
  const values = [
    researchData.taxon_id,
    researchData.general_description,
    researchData.native_adapted_habitats,
    researchData.stewardship_best_practices,
    researchData.planting_methods,
    researchData.ecological_function,
    researchData.agroforestry_use_cases,
    researchData.elevation_ranges,
    researchData.compatible_soil_types,
    researchData.conservation_status,
    ipfsCid,
    researcherWallet
  ];
  try {
    console.log('Storing research data in PostgreSQL...');
    await pool.query(query, values);
    console.log('Research data stored successfully.');
  } catch (error) {
    console.error('Error storing research data in PostgreSQL:', error.stack);
    throw error;
  }
}

// --- POST /ai/research Endpoint ---
// Expects a JSON payload with keys: scientificName, commonNames, researcherWallet.
// Uses scientificName as the TaxonID.
app.post('/ai/research', async (req, res) => {
  try {
    const { scientificName, commonNames, researcherWallet } = req.body;
    if (!scientificName || !commonNames || !researcherWallet) {
      return res.status(400).json({ error: 'Missing required fields: scientificName, commonNames, researcherWallet' });
    }
    
    // Use scientificName as the TaxonID.
    const taxonID = scientificName;

    // Trigger the AI research workflow (Perplexity + ChatGPT 4o)
    const researchData = await performAIResearch(taxonID, scientificName, commonNames, researcherWallet);

    // Upload the structured research JSON to IPFS via Lighthouse using Athus's module
    const ipfsCid = await uploadResearchToIPFS(researchData);

    // Store the research data in PostgreSQL (including ipfs_cid and researcher_wallet)
    await storeResearchInDB(researchData, ipfsCid, researcherWallet);

    // Trigger attestation and NFT minting via Athus's modules
    const attestationDetails = await triggerAttestationAndMint(researchData, ipfsCid, researcherWallet);

    // Combine research data with the attestation details returned by AgentKit and the IPFS CID
    const finalResponse = {
      ...researchData,
      ipfs_cid: ipfsCid,
      on_chain: attestationDetails
    };

    res.json({ status: "success", data: finalResponse });
  } catch (error) {
    console.error("Error in POST /ai/research endpoint:", error.stack);
    res.status(500).json({ error: "Internal server error", details: error.message });
  }
});

// --- GET /ai/research/:scientificName Endpoint ---
// Retrieves research data for the given scientificName (used as TaxonID).
app.get('/ai/research/:scientificName', async (req, res) => {
  const { scientificName } = req.params;
  try {
    const query = 'SELECT * FROM ai_research WHERE taxon_id = $1';
    const result = await pool.query(query, [scientificName]);
    if (result.rows.length === 0) {
      return res.status(404).json({ error: `No research data found for scientificName: ${scientificName}` });
    }
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error retrieving research data:', error.stack);
    res.status(500).json({ error: 'Internal server error.' });
  }
});

// --- Function: triggerAttestationAndMint ---
// Triggers attestation and NFT minting using Athus's modules.
async function triggerAttestationAndMint(researchData, ipfsCid, researcherWallet) {
  try {
    console.log("Creating attestation using Athus's module...");
    const attestationUID = await createAttestation();
    console.log("Attestation UID:", attestationUID);

    // Reuse the IPFS CID as the token URI.
    const tokenURI = ipfsCid;

    console.log("Minting NFT using Athus's mintNFTree module...");
    // Using the researcherWallet as recipient; tokenId 2 and amount 1 are examples.
    const mintReceipt = await mintNFTree(researcherWallet, 2, 1, tokenURI);
    console.log("Mint Receipt:", mintReceipt);

    return {
      attestation_id: attestationUID,
      attestation_metadata_ipfs: tokenURI,
      nft_mint_receipt: mintReceipt
    };
  } catch (error) {
    console.error("Error in triggerAttestationAndMint:", error.stack);
    throw error;
  }
}

// Start the Express server on port 3000 (or the port specified in .env)
const PORT = process.env.PORT || 3000;
app.listen(PORT, '0.0.0.0', () => {
  console.log(`AI Research API listening on port ${PORT}`);
});




================================================
File: ai-agent/server.js.save
================================================
// ai-agent/server.js

// Global error handlers to catch unhandled errors
process.on('uncaughtException', err => {
  console.error('Uncaught Exception:', err);
});
process.on('unhandledRejection', err => {
  console.error('Unhandled Rejection:', err);
});

// Load environment variables from the repository root .env file
require('dotenv').config({ path: '../.env' });
console.log("DB_HOST is:", process.env.DB_HOST);
console.log("LIGHTHOUSE_API_KEY is:", process.env.LIGHTHOUSE_API_KEY);

// Import required modules
const express = require('express');
const agentkit = require('@coinbase/agentkit');
const cors = require('cors');
const axios = require('axios');
const FormData = require('form-data');
const { Pool } = require('pg');

// Import the AI research service (Perplexity + ChatGPT 4o flow)
const { performAIResearch } = require('./aiResearchService');

// Create an Express application
const app = express();
app.use(cors());
app.use(express.json());

// Set up PostgreSQL connection pool using the DB_ variables from .env
const pool = new Pool({
  host: process.env.DB_HOST,
  port: process.env.DB_PORT,
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD
});

// --- Function: uploadToIPFS ---
// Uploads JSON data to IPFS via Lighthouse and returns the CID.
async function uploadToIPFS(jsonData) {
  const url = 'https://node.lighthouse.storage/api/v0/add?pin=true';
  
  // Create a FormData instance and append the JSON data as a file.
  const formData = new FormData();
  const buffer = Buffer.from(JSON.stringify(jsonData));
  formData.append('file', buffer, { filename: 'research.json', contentType: 'application/json' });
  
  // Set up headers including the Lighthouse API key with "Bearer" prefix.
  const headers = {
    ...formData.getHeaders(),
    'Authorization': `Bearer ${process.env.LIGHTHOUSE_API_KEY}`
  };

  try {
    console.log('Uploading research JSON to IPFS via Lighthouse...');
    const response = await axios.post(url, formData, { headers });
    const ipfsCid = response.data.Hash;
    console.log('Received IPFS CID from Lighthouse:', ipfsCid);
    return ipfsCid;
  } catch (error) {
    console.error('Error uploading to Lighthouse:', error.response ? error.response.data : error.message);
    throw error;
  }
}

// --- Function: storeResearchInDB ---
// Inserts the research data into the ai_research table.
async function storeResearchInDB(researchData, ipfsCid, researcherWallet) {
  const query = `
    INSERT INTO ai_research (
      taxon_id,
      general_description,
      native_adapted_habitats,
      stewardship_best_practices,
      planting_methods,
      ecological_function,
      agroforestry_use_cases,
      elevation_ranges,
      compatible_soil_types,
      conservation_status,
      research_status,
      ipfs_cid,
      researcher_wallet,
      revision,
      revision_history,
      created_at,
      updated_at
    ) VALUES (
      $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 'unverified', $11, $12, 1, '[]', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
    )
    ON CONFLICT (taxon_id) DO UPDATE SET
      general_description = EXCLUDED.general_description,
      native_adapted_habitats = EXCLUDED.native_adapted_habitats,
      stewardship_best_practices = EXCLUDED.stewardship_best_practices,
      planting_methods = EXCLUDED.planting_methods,
      ecological_function = EXCLUDED.ecological_function,
      agroforestry_use_cases = EXCLUDED.agroforestry_use_cases,
      elevation_ranges = EXCLUDED.elevation_ranges,
      compatible_soil_types = EXCLUDED.compatible_soil_types,
      conservation_status = EXCLUDED.conservation_status,
      research_status = 'unverified',
      ipfs_cid = EXCLUDED.ipfs_cid,
      researcher_wallet = EXCLUDED.researcher_wallet,
      updated_at = CURRENT_TIMESTAMP;
  `;
  const values = [
    researchData.taxon_id,
    researchData.general_description,
    researchData.native_adapted_habitats,
    researchData.stewardship_best_practices,
    researchData.planting_methods,
    researchData.ecological_function,
    researchData.agroforestry_use_cases,
    researchData.elevation_ranges,
    researchData.compatible_soil_types,
    researchData.conservation_status,
    ipfsCid,
    researcherWallet
  ];
  try {
    console.log('Storing research data in PostgreSQL...');
    await pool.query(query, values);
    console.log('Research data stored successfully.');
  } catch (error) {
    console.error('Error storing research data in PostgreSQL:', error);
    throw error;
  }
}

// --- POST /ai/research Endpoint ---
// Expects a JSON payload with keys: scientificName, commonNames, researcherWallet.
// Uses scientificName as the TaxonID.
app.post('/ai/research', async (req, res) => {
  try {
    const { scientificName, commonNames, researcherWallet } = req.body;
    if (!scientificName || !commonNames || !researcherWallet) {
      return res.status(400).json({ error: 'Missing required fields: scientificName, commonNames, researcherWallet' });
    }
    
    // Use scientificName as the TaxonID.
    const taxonID = scientificName;

    // Trigger the AI research workflow (Perplexity + ChatGPT 4o)
    const researchData = await performAIResearch(taxonID, scientificName, commonNames, researcherWallet);

    // Upload the structured research JSON to IPFS via Lighthouse
    const ipfsCid = await uploadToIPFS(researchData);

    // Store the research data in PostgreSQL (including ipfs_cid and researcher_wallet)
    await storeResearchInDB(researchData, ipfsCid, researcherWallet);

    // Trigger the AgentKit attestation transaction using the stored IPFS CID
    const attestationDetails = await triggerAgentKitAttestation(researchData, ipfsCid, researcherWallet);

    // Dummy on-chain details (to be replaced with actual on-chain actions later)
    const onChainDetails = {
      attestation_id: "dummy_attestation_id",
      nftree_token_id: "dummy_nftree_token_id",
      contreebution_token_id: "dummy_contreebution_token_id"
    };

    // Combine research data with on-chain details and IPFS CID, then return final JSON.
    const finalResponse = {
      ...researchData,
      ipfs_cid: ipfsCid,
      on_chain: attestationDetails
    };

    res.json({ status: "success", data: finalResponse });
  } catch (error) {
    console.error("Error in POST /ai/research endpoint:", error);
    res.status(500).json({ error: "Internal server error" });
  }
});

// --- GET /ai/research/:scientificName Endpoint ---
// Retrieves research data for the given scientificName (used as TaxonID).
app.get('/ai/research/:scientificName', async (req, res) => {
  const { scientificName } = req.params;
  try {
    const query = 'SELECT * FROM ai_research WHERE taxon_id = $1';
    const result = await pool.query(query, [scientificName]);
    if (result.rows.length === 0) {
      return res.status(404).json({ error: `No research data found for scientificName: ${scientificName}` });
    }
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error retrieving research data:', error);
    res.status(500).json({ error: 'Internal server error.' });
  }
});

// Start the Express server on port 3000 (or the port specified in .env)
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`AI Research API listening on port ${PORT}`);
});



================================================
File: ai-agent/server.js.save.1
================================================
// ai-agent/server.js

// Global error handlers to catch unhandled errors
process.on('uncaughtException', err => {
  console.error('Uncaught Exception:', err);
});
process.on('unhandledRejection', err => {
  console.error('Unhandled Rejection:', err);
});

// Load environment variables from the repository root .env file
require('dotenv').config({ path: '../.env' });
console.log("DB_HOST is:", process.env.DB_HOST);
console.log("LIGHTHOUSE_API_KEY is:", process.env.LIGHTHOUSE_API_KEY);

// Import required modules
const express = require('express');
const cors = require('cors');
const axios = require('axios');
const FormData = require('form-data');
const { Pool } = require('pg');
const { createAttestation } = require('../smart-contracts/createAttestation');
const { uploadToIPFS } = require('../smart-contracts/uploadToIPFS');
const { mintNFTree } = require('../smart-contracts/mintNFTree');
const path = require('path');


// Import the AI research service (Perplexity + ChatGPT 4o flow)
const { performAIResearch } = require('./aiResearchService');

// Create an Express application
const app = express();
app.use(cors());
app.use(express.json());

// Set up PostgreSQL connection pool using the DB_ variables from .env
const pool = new Pool({
  host: process.env.DB_HOST,
  port: process.env.DB_PORT,
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD
});

// --- Function: uploadToIPFS ---
// Uploads JSON data to IPFS via Lighthouse and returns the CID.
async function uploadToIPFS(jsonData) {
  const url = 'https://node.lighthouse.storage/api/v0/add?pin=true';
  
  // Create a FormData instance and append the JSON data as a file.
  const formData = new FormData();
  const buffer = Buffer.from(JSON.stringify(jsonData));
  formData.append('file', buffer, { filename: 'research.json', contentType: 'application/json' });
  
  // Set up headers including the Lighthouse API key with "Bearer" prefix.
  const headers = {
    ...formData.getHeaders(),
    'Authorization': `Bearer ${process.env.LIGHTHOUSE_API_KEY}`
  };

  try {
    console.log('Uploading research JSON to IPFS via Lighthouse...');
    const response = await axios.post(url, formData, { headers });
    const ipfsCid = response.data.Hash;
    console.log('Received IPFS CID from Lighthouse:', ipfsCid);
    return ipfsCid;
  } catch (error) {
    console.error('Error uploading to Lighthouse:', error.response ? error.response.data : error.message);
    throw error;
  }
}

// --- Function: storeResearchInDB ---
// Inserts the research data into the ai_research table.
async function storeResearchInDB(researchData, ipfsCid, researcherWallet) {
  const query = `
    INSERT INTO ai_research (
      taxon_id,
      general_description,
      native_adapted_habitats,
      stewardship_best_practices,
      planting_methods,
      ecological_function,
      agroforestry_use_cases,
      elevation_ranges,
      compatible_soil_types,
      conservation_status,
      research_status,
      ipfs_cid,
      researcher_wallet,
      revision,
      revision_history,
      created_at,
      updated_at
    ) VALUES (
      $1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 'unverified', $11, $12, 1, '[]', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP
    )
    ON CONFLICT (taxon_id) DO UPDATE SET
      general_description = EXCLUDED.general_description,
      native_adapted_habitats = EXCLUDED.native_adapted_habitats,
      stewardship_best_practices = EXCLUDED.stewardship_best_practices,
      planting_methods = EXCLUDED.planting_methods,
      ecological_function = EXCLUDED.ecological_function,
      agroforestry_use_cases = EXCLUDED.agroforestry_use_cases,
      elevation_ranges = EXCLUDED.elevation_ranges,
      compatible_soil_types = EXCLUDED.compatible_soil_types,
      conservation_status = EXCLUDED.conservation_status,
      research_status = 'unverified',
      ipfs_cid = EXCLUDED.ipfs_cid,
      researcher_wallet = EXCLUDED.researcher_wallet,
      updated_at = CURRENT_TIMESTAMP;
  `;
  const values = [
    researchData.taxon_id,
    researchData.general_description,
    researchData.native_adapted_habitats,
    researchData.stewardship_best_practices,
    researchData.planting_methods,
    researchData.ecological_function,
    researchData.agroforestry_use_cases,
    researchData.elevation_ranges,
    researchData.compatible_soil_types,
    researchData.conservation_status,
    ipfsCid,
    researcherWallet
  ];
  try {
    console.log('Storing research data in PostgreSQL...');
    await pool.query(query, values);
    console.log('Research data stored successfully.');
  } catch (error) {
    console.error('Error storing research data in PostgreSQL:', error);
    throw error;
  }
}

// --- POST /ai/research Endpoint ---
// Expects a JSON payload with keys: scientificName, commonNames, researcherWallet.
// Uses scientificName as the TaxonID.
app.post('/ai/research', async (req, res) => {
  try {
    const { scientificName, commonNames, researcherWallet } = req.body;
    if (!scientificName || !commonNames || !researcherWallet) {
      return res.status(400).json({ error: 'Missing required fields: scientificName, commonNames, researcherWallet' });
    }
    
    // Use scientificName as the TaxonID.
    const taxonID = scientificName;

    // Trigger the AI research workflow (Perplexity + ChatGPT 4o)
    const researchData = await performAIResearch(taxonID, scientificName, commonNames, researcherWallet);

    // Upload the structured research JSON to IPFS via Lighthouse
    const ipfsCid = await uploadToIPFS(researchData);

    // Store the research data in PostgreSQL (including ipfs_cid and researcher_wallet)
    await storeResearchInDB(researchData, ipfsCid, researcherWallet);

    // Dummy on-chain details (to be replaced with actual on-chain actions later)
    const onChainDetails = {
      attestation_id: "dummy_attestation_id",
      nftree_token_id: "dummy_nftree_token_id",
      contreebution_token_id: "dummy_contreebution_token_id"
    };

    // Combine research data with on-chain details and IPFS CID, then return final JSON.
    const finalResponse = {
      ...researchData,
      ipfs_cid: ipfsCid,
      on_chain: onChainDetails
    };

    res.json({ status: "success", data: finalResponse });
  } catch (error) {
    console.error("Error in POST /ai/research endpoint:", error);
    res.status(500).json({ error: "Internal server error" });
  }
});

// --- GET /ai/research/:scientificName Endpoint ---
// Retrieves research data for the given scientificName (used as TaxonID).
app.get('/ai/research/:scientificName', async (req, res) => {
  const { scientificName } = req.params;
  try {
    const query = 'SELECT * FROM ai_research WHERE taxon_id = $1';
    const result = await pool.query(query, [scientificName]);
    if (result.rows.length === 0) {
      return res.status(404).json({ error: `No research data found for scientificName: ${scientificName}` });
    }
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error retrieving research data:', error);
    res.status(500).json({ error: 'Internal server error.' });
  }
});

// Start the Express server on port 3000 (or the port specified in .env)
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
  console.log(`AI Research API listening on port ${PORT}`);
});



================================================
File: ai-agent/testAIResearch.js
================================================
const { performAIResearch } = require('./aiResearchService');

// Test parameters (replace these with your test values if needed)
const taxonID = "Acacia_dealbata_test";
const scientificName = "Acacia dealbata";
const commonNames = ["Silver Wattle", "Mimosa"];
const researcherWallet = "0x1234567890abcdef1234567890abcdef12345678";

performAIResearch(taxonID, scientificName, commonNames, researcherWallet)
  .then(result => {
    console.log("Final Structured Research Data:");
    console.log(JSON.stringify(result, null, 2));
  })
  .catch(err => {
    console.error("Error during AI research test:", err);
  });



================================================
File: backend/README.md
================================================
# Backend



================================================
File: backend/API_DOCS.md
================================================
Begin copying here (everything between the triple backticks):

markdown
Copy
Edit
# DeepTrees API Documentation

This document outlines the available API endpoints for the DeepTrees project, **hosted at**:
http://64.227.23.153:3000

markdown
Copy
Edit
*(Replace with your actual domain or IP if different.)*

---

## Table of Contents

1. [Overview](#overview)  
2. [Base URL](#base-url)  
3. [Endpoints](#endpoints)  
   - [GET / (Health Check)](#get--health-check)  
   - [POST /ai/research](#post-airesearch)  
   - [GET /ai/research/:scientificName](#get-airesearchscientificname)  
4. [Example Usage](#example-usage)  
   - [POST /ai/research via cURL](#post-airesearch-via-curl)  
   - [GET /ai/research/:scientificName via cURL](#get-airesearchscientificname-via-curl)  
5. [Notes & Future Plans](#notes--future-plans)

---

## Overview

DeepTrees is an AI-driven Web3 platform that aggregates, structures, and tokenizes scientific knowledge about tree species. This API allows you to:

1. **Initiate AI Research** with `POST /ai/research`  
   - Gathers data via Perplexity.  
   - Refines results via ChatGPT 4o.  
   - Uploads structured JSON to IPFS (Lighthouse).  
   - Stores final data in PostgreSQL.

2. **Retrieve Stored Research** with `GET /ai/research/:scientificName`  
   - Fetch data for a specific species using its scientific name.

*(Future endpoints will cover on-chain attestations and NFT minting.)*

---

## Base URL

Our API is currently running on **port 3000** at the following IP address:
http://64.227.23.153:3000

yaml
Copy
Edit
> **Note:**  
> - If the service is not responding externally, ensure your firewall settings allow inbound requests on port 3000.  
> - In a production environment, youâ€™d typically secure this with HTTPS and use a custom domain.

---

## Endpoints

### GET / (Health Check)

**URL:**  
GET /

makefile
Copy
Edit
**Description:**  
Returns a simple message confirming the API is running.

**Response:**  
DeepTrees API is running.

yaml
Copy
Edit

---

### POST /ai/research

**URL:**  
POST /ai/research

swift
Copy
Edit

**Description:**  
Triggers the AI research workflow. Uses the provided `scientificName` (treated as our internal `taxon_id`), along with `commonNames` and `researcherWallet`. Results in a structured JSON record stored in PostgreSQL, plus a CID from IPFS.

**Request Body:**  
```json
{
  "scientificName": "string (required)",
  "commonNames": ["array of strings (required)"],
  "researcherWallet": "string (required, e.g., 0xYourWalletAddress)"
}
Field	Type	Description
scientificName	string	Unique name, e.g. "Quercus robur"
commonNames	array of string	List of common names, e.g. ["English Oak", "Pedunculate Oak"]
researcherWallet	string	Ethereum wallet address of the researcher
Sample Response:

json
Copy
Edit
{
  "status": "success",
  "data": {
    "taxon_id": "Quercus robur",
    "general_description": "AI-generated description...",
    "native_adapted_habitats": "...",
    "stewardship_best_practices": "...",
    "planting_methods": "...",
    "ecological_function": "...",
    "agroforestry_use_cases": "...",
    "elevation_ranges": "...",
    "compatible_soil_types": "...",
    "conservation_status": "...",
    "ipfs_cid": "Qm...CID",
    "on_chain": {
      "attestation_id": "dummy_attestation_id",
      "nftree_token_id": "dummy_nftree_token_id",
      "contreebution_token_id": "dummy_contreebution_token_id"
    }
  }
}
GET /ai/research/:scientificName
URL:

bash
Copy
Edit
GET /ai/research/{scientificName}
(URL-encode spaces if needed.)

Description:
Fetches a stored research record for the specified scientificName.

Response Example:

json
Copy
Edit
{
  "taxon_id": "Quercus robur",
  "general_description": "AI-generated description...",
  "native_adapted_habitats": "...",
  "stewardship_best_practices": "...",
  "planting_methods": "...",
  "ecological_function": "...",
  "agroforestry_use_cases": "...",
  "elevation_ranges": "...",
  "compatible_soil_types": "...",
  "conservation_status": "...",
  "research_status": "unverified",
  "ipfs_cid": "Qm...CID",
  "researcher_wallet": "0xYourWalletAddress",
  "created_at": "2025-02-08T19:37:54.072Z",
  "updated_at": "2025-02-08T19:37:54.072Z",
  "revision": 1,
  "revision_history": "[]"
}
If no record is found, returns:

json
Copy
Edit
{
  "error": "No research data found for scientificName: Quercus robur"
}
Example Usage
POST /ai/research via cURL
bash
Copy
Edit
curl -X POST http://64.227.23.153:3000/ai/research \
  -H "Content-Type: application/json" \
  -d '{
    "scientificName": "Quercus robur",
    "commonNames": ["English Oak", "Pedunculate Oak"],
    "researcherWallet": "0xYourWalletAddress"
  }'
Expected Response: JSON with status: "success" and an embedded data object containing AI-generated fields, IPFS CID, and dummy on-chain details.

GET /ai/research/:scientificName via cURL
bash
Copy
Edit
curl http://64.227.23.153:3000/ai/research/Quercus%20robur
Expected Response: JSON object with the stored research details.

Notes & Future Plans
Authentication & Security:
Currently, there is no API key or token-based authentication. In a real production environment, you should secure this service (e.g., require an API key, use HTTPS).

On-Chain Actions:
The on_chain object returns dummy data. Soon, we will integrate real on-chain attestations and NFT minting via AgentKit. Endpoints like POST /attest/research and POST /mint/nftree are planned.

Error Handling:
We use standard HTTP response codes (e.g., 400, 404, 500). The client must handle these appropriately.

Updates & Revisions:
Each time POST /ai/research is called with the same scientificName, the data is updated (and the revision increments in the ai_research table).



================================================
File: backup/server.js
================================================
// backend/server.js

// Load environment variables from the root .env file
require('dotenv').config({ path: '../.env' });

const express = require('express');
const cors = require('cors');
const { Pool } = require('pg');
const axios = require('axios');
const FormData = require('form-data');

// Import the AI research function from your ai-agent folder
const { performAIResearch } = require('../ai-agent/aiResearchService');

const app = express();
app.use(cors());
const port = process.env.PORT || 3000;

// Parse JSON request bodies
app.use(express.json());

// Setup PostgreSQL connection pool using environment variables
const pool = new Pool({
  host: process.env.DB_HOST,
  port: parseInt(process.env.DB_PORT, 10),
  database: process.env.DB_NAME,
  user: process.env.DB_USER,
  password: process.env.DB_PASSWORD,
});

// -----------------------------------------------------------------
// Basic health-check endpoint
app.get('/', (req, res) => {
  res.send('DeepTrees PostgreSQL API is running.');
});

// GET /research/species/:taxonID
// Retrieves a research record for the given taxonID
app.get('/research/species/:taxonID', async (req, res) => {
  const { taxonID } = req.params;
  try {
    const query = 'SELECT * FROM ai_research WHERE taxon_id = $1';
    const result = await pool.query(query, [taxonID]);
    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Species not found.' });
    }
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error retrieving research data:', error);
    res.status(500).json({ error: 'Internal server error.' });
  }
});

// POST /research/species
// Inserts a new research record or updates an existing one (upsert)
app.post('/research/species', async (req, res) => {
  const {
    taxon_id,
    general_description,
    native_adapted_habitats,
    stewardship_best_practices,
    planting_methods,
    ecological_function,
    agroforestry_use_cases,
    elevation_ranges,
    compatible_soil_types,
    conservation_status,
    research_status,
    ipfs_cid,
    researcher_wallet,
  } = req.body;

  // Basic validation
  if (!taxon_id || !general_description) {
    return res.status(400).json({ error: 'taxon_id and general_description are required.' });
  }

  try {
    const query = `
      INSERT INTO ai_research
        (taxon_id, general_description, native_adapted_habitats, stewardship_best_practices, planting_methods,
         ecological_function, agroforestry_use_cases, elevation_ranges, compatible_soil_types, conservation_status,
         research_status, ipfs_cid, researcher_wallet, created_at, updated_at, revision)
      VALUES
        ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, NOW(), NOW(), 1)
      ON CONFLICT (taxon_id) DO UPDATE SET
         general_description = EXCLUDED.general_description,
         native_adapted_habitats = EXCLUDED.native_adapted_habitats,
         stewardship_best_practices = EXCLUDED.stewardship_best_practices,
         planting_methods = EXCLUDED.planting_methods,
         ecological_function = EXCLUDED.ecological_function,
         agroforestry_use_cases = EXCLUDED.agroforestry_use_cases,
         elevation_ranges = EXCLUDED.elevation_ranges,
         compatible_soil_types = EXCLUDED.compatible_soil_types,
         conservation_status = EXCLUDED.conservation_status,
         research_status = EXCLUDED.research_status,
         ipfs_cid = EXCLUDED.ipfs_cid,
         researcher_wallet = EXCLUDED.researcher_wallet,
         updated_at = NOW(),
         revision = ai_research.revision + 1
      RETURNING *;
    `;
    const values = [
      taxon_id,
      general_description,
      native_adapted_habitats || null,
      stewardship_best_practices || null,
      planting_methods || null,
      ecological_function || null,
      agroforestry_use_cases || null,
      elevation_ranges || null,
      compatible_soil_types || null,
      conservation_status || null,
      research_status || 'unverified',
      ipfs_cid || null,
      researcher_wallet || null,
    ];
    const result = await pool.query(query, values);
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Error inserting/updating research data:', error);
    res.status(500).json({ error: 'Internal server error.' });
  }
});

// -----------------------------------------------------------------
// Helper function: Upload JSON to IPFS using Lighthouse
async function uploadToIPFS(jsonData) {
  const formData = new FormData();
  formData.append('file', Buffer.from(JSON.stringify(jsonData)), {
    filename: 'research.json',
    contentType: 'application/json',
  });

  try {
    const response = await axios.post(
      'https://node.lighthouse.storage/api/v0/add?pin=true',
      formData,
      {
        headers: {
          'Authorization': `Bearer ${process.env.LIGHTHOUSE_API_KEY}`,
          ...formData.getHeaders(),
        },
      }
    );
    // Expect response.data.Hash to contain the IPFS CID
    return response.data.Hash;
  } catch (error) {
    console.error('Error uploading to IPFS:', error);
    throw error;
  }
}

// -----------------------------------------------------------------
// New Endpoint: POST /ai/research
// This endpoint triggers the complete AI research workflow:
// 1. Call the AI research agent (Perplexity + GPTâ€‘4)
// 2. Upload the resulting JSON to IPFS
// 3. Upsert the research data into PostgreSQL
// 4. Return the research data with dummy onâ€‘chain details
app.post('/ai/research', async (req, res) => {
  const { taxonID, scientificName, commonNames, researcherWallet } = req.body;

  if (!taxonID || !scientificName || !commonNames || !researcherWallet) {
    return res.status(400).json({
      error: 'Missing required fields: taxonID, scientificName, commonNames, researcherWallet.'
    });
  }

  try {
    // Step 1: Call the AI Research Agent
    // (This function should perform the Perplexity search and GPTâ€‘4 JSON formatting)
    const researchData = await performAIResearch(taxonID, scientificName, commonNames, researcherWallet);
    // researchData is expected to be an object with fields like general_description, etc.

    // Step 2: Upload the structured JSON to IPFS
    const ipfsCid = await uploadToIPFS(researchData);

    // Append IPFS CID and researcher wallet to the research data
    researchData.ipfs_cid = ipfsCid;
    researchData.researcher_wallet = researcherWallet;
    researchData.taxon_id = taxonID;
    researchData.research_status = researchData.research_status || 'unverified';

    // Step 3: Upsert the research record into PostgreSQL
    const query = `
      INSERT INTO ai_research
        (taxon_id, general_description, native_adapted_habitats, stewardship_best_practices, planting_methods,
         ecological_function, agroforestry_use_cases, elevation_ranges, compatible_soil_types, conservation_status,
         research_status, ipfs_cid, researcher_wallet, created_at, updated_at, revision)
      VALUES
        ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, NOW(), NOW(), 1)
      ON CONFLICT (taxon_id) DO UPDATE SET
         general_description = EXCLUDED.general_description,
         native_adapted_habitats = EXCLUDED.native_adapted_habitats,
         stewardship_best_practices = EXCLUDED.stewardship_best_practices,
         planting_methods = EXCLUDED.planting_methods,
         ecological_function = EXCLUDED.ecological_function,
         agroforestry_use_cases = EXCLUDED.agroforestry_use_cases,
         elevation_ranges = EXCLUDED.elevation_ranges,
         compatible_soil_types = EXCLUDED.compatible_soil_types,
         conservation_status = EXCLUDED.conservation_status,
         research_status = EXCLUDED.research_status,
         ipfs_cid = EXCLUDED.ipfs_cid,
         researcher_wallet = EXCLUDED.researcher_wallet,
         updated_at = NOW(),
         revision = ai_research.revision + 1
      RETURNING *;
    `;
    const values = [
      taxonID,
      researchData.general_description,
      researchData.native_adapted_habitats || null,
      researchData.stewardship_best_practices || null,
      researchData.planting_methods || null,
      researchData.ecological_function || null,
      researchData.agroforestry_use_cases || null,
      researchData.elevation_ranges || null,
      researchData.compatible_soil_types || null,
      researchData.conservation_status || null,
      researchData.research_status,
      ipfsCid,
      researcherWallet,
    ];
    const dbResult = await pool.query(query, values);

    // Step 4: Return the final response including dummy on-chain details
    const finalResponse = {
      ...dbResult.rows[0],
      attestation_id: "dummy_attestation_id",
      nft_token_ids: {
        NFTree: "dummy_nftree_token",
        Contreebution: "dummy_contreebution_token"
      }
    };

    res.json(finalResponse);
  } catch (error) {
    console.error('Error in /ai/research endpoint:', error);
    res.status(500).json({ error: 'Internal server error in AI research workflow.' });
  }
});

// -----------------------------------------------------------------
// Start the Express server
app.listen(port, () => {
  console.log(`DeepTrees API is listening on port ${port}`);
});



================================================
File: database/db_schema.sql
================================================
-- db_schema.sql
-- PostgreSQL Schema Definitions for DeepTrees AI Research Data

CREATE TABLE ai_research (
    taxon_id VARCHAR(50) PRIMARY KEY,
    general_description TEXT,
    native_adapted_habitats TEXT,
    stewardship_best_practices TEXT,
    planting_methods TEXT,
    ecological_function TEXT,
    agroforestry_use_cases TEXT,
    elevation_ranges TEXT,
    compatible_soil_types TEXT,
    conservation_status TEXT,
    research_status VARCHAR(20) DEFAULT 'unverified',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    revision INT DEFAULT 1,
    revision_history JSONB
);



================================================
File: docs/README.md
================================================
# Documentation




================================================
File: smart-contracts/README.md
================================================
# Smart Contracts



================================================
File: smart-contracts/NFTree.sol
================================================
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.20;

import "@openzeppelin/contracts/token/ERC1155/ERC1155.sol";
import "@openzeppelin/contracts/access/Ownable.sol";
import "@openzeppelin/contracts/token/ERC1155/extensions/ERC1155Burnable.sol";
import "@openzeppelin/contracts/utils/Strings.sol";
import "@openzeppelin/contracts/utils/Base64.sol"; // Import Base64 library

contract NFTree is ERC1155, Ownable, ERC1155Burnable {
    using Strings for uint256;

    // Fixed image URL for all NFTs
    string private constant _baseImageURI =
        "ipfs.io/ipfs/bafkreialkdkavmvykebueokxjtzsu3djas6y5lpxrrecw2n3k67xqcu4sm";

    // Mapping from token ID to its IPFS CID (current CID) - Now used for metadata, but kept for history
    mapping(uint256 => string) private _tokenCIDs;

    // Mapping from token ID to an array of historical IPFS CIDs
    mapping(uint256 => string[]) private _tokenCIDHistory;

    constructor(address initialOwner) ERC1155("TreeNFT") Ownable(initialOwner) {
        // Set the base URI to ensure metadata consistency. Important for marketplaces.
        _setURI("ipfs://your_base_uri/"); // Replace with your desired base URI (e.g., for JSON files)
    }

    /**
     * @dev Sets the base URI for all tokens. Consider if you REALLY need this, given the fixed image.
     * It's primarily for the JSON metadata file if you use one.
     */
    function setURI(string memory newuri) public onlyOwner {
        _setURI(newuri);
    }

    /**
     * @dev Mints `amount` tokens of type `id` to `account` and associates it with an IPFS CID (stored for history).
     * The metadata (including image) is now standardized.
     */
    function mint(
        address account,
        uint256 id,
        uint256 amount,
        string memory ipfsCID
    ) public onlyOwner {
        // Mint the tokens
        _mint(account, id, amount, "");
        // Store the IPFS CID for the token ID (for history)
        _tokenCIDs[id] = ipfsCID; // Keep this if you want to track *why* a token was minted.
        // Add the CID to the history
        _tokenCIDHistory[id].push(ipfsCID);
    }

    /**
     * @dev Batch mints multiple token types to `to`, each with their own IPFS CID (stored for history).
     * The metadata (including image) is now standardized.
     */
    function mintBatch(
        address to,
        uint256[] memory ids,
        uint256[] memory amounts,
        string[] memory ipfsCIDs
    ) public onlyOwner {
        require(
            ids.length == ipfsCIDs.length,
            "TreeNFT: ids and ipfsCIDs length mismatch"
        );
        // Mint the tokens in batch
        _mintBatch(to, ids, amounts, "");
        // Update the IPFS CIDs for each token ID (for history)
        for (uint256 i = 0; i < ids.length; ++i) {
            uint256 id = ids[i];
            string memory ipfsCID = ipfsCIDs[i];
            // Store the IPFS CID for the token ID
            _tokenCIDs[id] = ipfsCID;
            // Add the CID to the history
            _tokenCIDHistory[id].push(ipfsCID);
        }
    }

    /**
     * @dev Returns the current IPFS CID associated with a given token ID (historical reason).
     */
    function getTokenCID(uint256 id) public view returns (string memory) {
        return _tokenCIDs[id];
    }

    /**
     * @dev Returns the entire history of IPFS CIDs associated with a given token ID.
     */
    function getTokenCIDHistory(uint256 id)
        public
        view
        returns (string[] memory)
    {
        return _tokenCIDHistory[id];
    }

    
}



================================================
File: smart-contracts/abi.json
================================================
[
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "initialOwner",
				"type": "address"
			}
		],
		"stateMutability": "nonpayable",
		"type": "constructor"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "sender",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "balance",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "needed",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "tokenId",
				"type": "uint256"
			}
		],
		"name": "ERC1155InsufficientBalance",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "approver",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidApprover",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "idsLength",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "valuesLength",
				"type": "uint256"
			}
		],
		"name": "ERC1155InvalidArrayLength",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidOperator",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "receiver",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidReceiver",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "sender",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidSender",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "owner",
				"type": "address"
			}
		],
		"name": "ERC1155MissingApprovalForAll",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "owner",
				"type": "address"
			}
		],
		"name": "OwnableInvalidOwner",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			}
		],
		"name": "OwnableUnauthorizedAccount",
		"type": "error"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"indexed": false,
				"internalType": "bool",
				"name": "approved",
				"type": "bool"
			}
		],
		"name": "ApprovalForAll",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "previousOwner",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "newOwner",
				"type": "address"
			}
		],
		"name": "OwnershipTransferred",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"indexed": false,
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"indexed": false,
				"internalType": "uint256[]",
				"name": "values",
				"type": "uint256[]"
			}
		],
		"name": "TransferBatch",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"indexed": false,
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"indexed": false,
				"internalType": "uint256",
				"name": "value",
				"type": "uint256"
			}
		],
		"name": "TransferSingle",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": false,
				"internalType": "string",
				"name": "value",
				"type": "string"
			},
			{
				"indexed": true,
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "URI",
		"type": "event"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "balanceOf",
		"outputs": [
			{
				"internalType": "uint256",
				"name": "",
				"type": "uint256"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address[]",
				"name": "accounts",
				"type": "address[]"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			}
		],
		"name": "balanceOfBatch",
		"outputs": [
			{
				"internalType": "uint256[]",
				"name": "",
				"type": "uint256[]"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "value",
				"type": "uint256"
			}
		],
		"name": "burn",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"internalType": "uint256[]",
				"name": "values",
				"type": "uint256[]"
			}
		],
		"name": "burnBatch",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "getTokenCID",
		"outputs": [
			{
				"internalType": "string",
				"name": "",
				"type": "string"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "getTokenCIDHistory",
		"outputs": [
			{
				"internalType": "string[]",
				"name": "",
				"type": "string[]"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			}
		],
		"name": "isApprovedForAll",
		"outputs": [
			{
				"internalType": "bool",
				"name": "",
				"type": "bool"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "amount",
				"type": "uint256"
			},
			{
				"internalType": "string",
				"name": "ipfsCID",
				"type": "string"
			}
		],
		"name": "mint",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"internalType": "uint256[]",
				"name": "amounts",
				"type": "uint256[]"
			},
			{
				"internalType": "string[]",
				"name": "ipfsCIDs",
				"type": "string[]"
			}
		],
		"name": "mintBatch",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [],
		"name": "owner",
		"outputs": [
			{
				"internalType": "address",
				"name": "",
				"type": "address"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [],
		"name": "renounceOwnership",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"internalType": "uint256[]",
				"name": "values",
				"type": "uint256[]"
			},
			{
				"internalType": "bytes",
				"name": "data",
				"type": "bytes"
			}
		],
		"name": "safeBatchTransferFrom",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "value",
				"type": "uint256"
			},
			{
				"internalType": "bytes",
				"name": "data",
				"type": "bytes"
			}
		],
		"name": "safeTransferFrom",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"internalType": "bool",
				"name": "approved",
				"type": "bool"
			}
		],
		"name": "setApprovalForAll",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "string",
				"name": "newuri",
				"type": "string"
			}
		],
		"name": "setURI",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "bytes4",
				"name": "interfaceId",
				"type": "bytes4"
			}
		],
		"name": "supportsInterface",
		"outputs": [
			{
				"internalType": "bool",
				"name": "",
				"type": "bool"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "newOwner",
				"type": "address"
			}
		],
		"name": "transferOwnership",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "",
				"type": "uint256"
			}
		],
		"name": "uri",
		"outputs": [
			{
				"internalType": "string",
				"name": "",
				"type": "string"
			}
		],
		"stateMutability": "view",
		"type": "function"
	}
]


================================================
File: smart-contracts/createAttestation.js
================================================
require('dotenv').config(); // Load environment variables from .env
const { EAS, NO_EXPIRATION, SchemaEncoder } = require('@ethereum-attestation-service/eas-sdk');
const { JsonRpcProvider, ethers } = require('ethers');

// Load environment variables
const EAS_CONTRACT_ADDRESS = process.env.EAS_CONTRACT_ADDRESS;
const _privateKey = process.env.AGENTKIT_WALLET_PRIVATE_KEY;  // Use your admin wallet's private key
const RPC_URL = process.env.BASE_L2_RPC_URL; // Use the Base L2 RPC URL from your .env
const SCHEMA_UID = process.env.SCHEMA_UID;

// Initialize the provider and signer
const provider = new JsonRpcProvider(RPC_URL);
let _chainId; // Declare _chainId outside the promise scope

provider.getNetwork().then(network => {
  _chainId = Number(network.chainId);
  console.log('Network Chain ID:', _chainId);
  console.log('Network Name:', network.name);
});
const signer = new ethers.Wallet(_privateKey, provider);

// Debug environment variables
console.log('EAS_CONTRACT_ADDRESS:', EAS_CONTRACT_ADDRESS);
console.log('SCHEMA_UID:', SCHEMA_UID);
console.log('RPC_URL:', RPC_URL);

// Initialize the EAS SDK
const eas = new EAS(EAS_CONTRACT_ADDRESS);
eas.connect(signer);

// Initialize SchemaEncoder with schema string
const schemaEncoder = new SchemaEncoder(
  'uint256 researchLogID, address triggerWallet, string scientificName, string speciesUID, string[] speciesURL, string llmModel, string ipfsCID, uint16 numberInsights, uint16 numberCitations'
);
const encodedData = schemaEncoder.encodeData([
  { name: 'researchLogID', value: 9374445464563, type: 'uint256' },
  { name: 'triggerWallet', value: '0xf703e22985579d53284648Ba4C56735d6B746c2d', type: 'address' },
  { name: 'scientificName', value: 'STeste 9', type: 'string' },
  { name: 'speciesUID', value: 'egdrgylidfclhhayfjteag4wef', type: 'string' },
  { name: 'speciesURL', value: ['https://example.com'], type: 'string[]' },
  { name: 'llmModel', value: 'GPT-4', type: 'string' },
  { name: 'ipfsCID', value: 'ipfs.io/ipfs/QmExampleCID', type: 'string' },
  { name: 'numberInsights', value: 96, type: 'uint16' },
  { name: 'numberCitations', value: 51, type: 'uint16' }
]);

// Function to create an attestation (attestation address is hardcoded for now)
async function createAttestation() {
  try {
    const transaction = await eas.attest({
      schema: SCHEMA_UID,
      data: {
        recipient: '0xf703e22985579d53284648Ba4C56735d6B746c2d', // Hardcoded attestation address
        expirationTime: NO_EXPIRATION,
        revocable: false,
        data: encodedData,
      },
    });

    const attestationUID = await transaction.wait(); // Wait for transaction receipt
    console.log("AttestationUID:", attestationUID);
    return attestationUID; // Return the AttestationUID
  } catch (error) {
    console.error('Error creating attestation:', error);
    if (error.attestationUID) {
      console.error('Error Receipt:', error.attestationUID);
    }
    throw error; // Re-throw the error for external handling
  }
}

require('dotenv').config(); // Load environment variables from .env
const { EAS, NO_EXPIRATION, SchemaEncoder } = require('@ethereum-attestation-service/eas-sdk');
const { JsonRpcProvider, ethers } = require('ethers');

// Load environment variables
const EAS_CONTRACT_ADDRESS = process.env.EAS_CONTRACT_ADDRESS;
const _privateKey = process.env.AGENTKIT_WALLET_PRIVATE_KEY;  // Use your admin wallet's private key
const RPC_URL = process.env.BASE_L2_RPC_URL; // Use the Base L2 RPC URL from your .env
const SCHEMA_UID = process.env.SCHEMA_UID;

// Initialize the provider and signer
const provider = new JsonRpcProvider(RPC_URL);
let _chainId; // Declare _chainId outside the promise scope

provider.getNetwork().then(network => {
  _chainId = Number(network.chainId);
  console.log('Network Chain ID:', _chainId);
  console.log('Network Name:', network.name);
});
const signer = new ethers.Wallet(_privateKey, provider);

// Debug environment variables
console.log('EAS_CONTRACT_ADDRESS:', EAS_CONTRACT_ADDRESS);
console.log('SCHEMA_UID:', SCHEMA_UID);
console.log('RPC_URL:', RPC_URL);

// Initialize the EAS SDK
const eas = new EAS(EAS_CONTRACT_ADDRESS);
eas.connect(signer);

// Initialize SchemaEncoder with schema string
const schemaEncoder = new SchemaEncoder(
  'uint256 researchLogID, address triggerWallet, string scientificName, string speciesUID, string[] speciesURL, string llmModel, string ipfsCID, uint16 numberInsights, uint16 numberCitations'
);
const encodedData = schemaEncoder.encodeData([
  { name: 'researchLogID', value: 9374445464563, type: 'uint256' },
  { name: 'triggerWallet', value: '0xf703e22985579d53284648Ba4C56735d6B746c2d', type: 'address' },
  { name: 'scientificName', value: 'STeste 9', type: 'string' },
  { name: 'speciesUID', value: 'egdrgylidfclhhayfjteag4wef', type: 'string' },
  { name: 'speciesURL', value: ['https://example.com'], type: 'string[]' },
  { name: 'llmModel', value: 'GPT-4', type: 'string' },
  { name: 'ipfsCID', value: 'ipfs.io/ipfs/QmExampleCID', type: 'string' },
  { name: 'numberInsights', value: 96, type: 'uint16' },
  { name: 'numberCitations', value: 51, type: 'uint16' }
]);

// Function to create an attestation (attestation address is hardcoded for now)
async function createAttestation() {
  try {
    const transaction = await eas.attest({
      schema: SCHEMA_UID,
      data: {
        recipient: '0xf703e22985579d53284648Ba4C56735d6B746c2d', // Hardcoded attestation address
        expirationTime: NO_EXPIRATION,
        revocable: false,
        data: encodedData,
      },
    });

    const attestationUID = await transaction.wait(); // Wait for transaction receipt
    console.log("AttestationUID:", attestationUID);
    return attestationUID; // Return the AttestationUID
  } catch (error) {
    console.error('Error creating attestation:', error);
    if (error.attestationUID) {
      console.error('Error Receipt:', error.attestationUID);
    }
    throw error; // Re-throw the error for external handling
  }
}

module.exports = { createAttestation };



================================================
File: smart-contracts/mintNFTree.js
================================================
require('dotenv').config();
const { ethers } = require("ethers");

// Environment variables
const RPC_URL = process.env.BASE_L2_RPC_URL;
const NFTree_CONTRACT_ADDRESS = process.env.NFTREE_CONTRACT_ADDRESS;
const PRIVATE_KEY = process.env.AGENTKIT_WALLET_PRIVATE_KEY;

// Validate environment variables
if (!RPC_URL || !NFTree_CONTRACT_ADDRESS || !PRIVATE_KEY) {
  throw new Error("Please configure the environment variables RPC_URL, NFTREE_CONTRACT_ADDRESS, and PRIVATE_KEY in the .env file.");
}

// ABI for the ERC-1155 contract
const NFTree_ABI = [
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "initialOwner",
				"type": "address"
			}
		],
		"stateMutability": "nonpayable",
		"type": "constructor"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "sender",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "balance",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "needed",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "tokenId",
				"type": "uint256"
			}
		],
		"name": "ERC1155InsufficientBalance",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "approver",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidApprover",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "idsLength",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "valuesLength",
				"type": "uint256"
			}
		],
		"name": "ERC1155InvalidArrayLength",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidOperator",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "receiver",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidReceiver",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "sender",
				"type": "address"
			}
		],
		"name": "ERC1155InvalidSender",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "owner",
				"type": "address"
			}
		],
		"name": "ERC1155MissingApprovalForAll",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "owner",
				"type": "address"
			}
		],
		"name": "OwnableInvalidOwner",
		"type": "error"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			}
		],
		"name": "OwnableUnauthorizedAccount",
		"type": "error"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"indexed": false,
				"internalType": "bool",
				"name": "approved",
				"type": "bool"
			}
		],
		"name": "ApprovalForAll",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "previousOwner",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "newOwner",
				"type": "address"
			}
		],
		"name": "OwnershipTransferred",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"indexed": false,
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"indexed": false,
				"internalType": "uint256[]",
				"name": "values",
				"type": "uint256[]"
			}
		],
		"name": "TransferBatch",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": true,
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"indexed": true,
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"indexed": false,
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"indexed": false,
				"internalType": "uint256",
				"name": "value",
				"type": "uint256"
			}
		],
		"name": "TransferSingle",
		"type": "event"
	},
	{
		"anonymous": false,
		"inputs": [
			{
				"indexed": false,
				"internalType": "string",
				"name": "value",
				"type": "string"
			},
			{
				"indexed": true,
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "URI",
		"type": "event"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "balanceOf",
		"outputs": [
			{
				"internalType": "uint256",
				"name": "",
				"type": "uint256"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address[]",
				"name": "accounts",
				"type": "address[]"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			}
		],
		"name": "balanceOfBatch",
		"outputs": [
			{
				"internalType": "uint256[]",
				"name": "",
				"type": "uint256[]"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "value",
				"type": "uint256"
			}
		],
		"name": "burn",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"internalType": "uint256[]",
				"name": "values",
				"type": "uint256[]"
			}
		],
		"name": "burnBatch",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "getTokenCID",
		"outputs": [
			{
				"internalType": "string",
				"name": "",
				"type": "string"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			}
		],
		"name": "getTokenCIDHistory",
		"outputs": [
			{
				"internalType": "string[]",
				"name": "",
				"type": "string[]"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			}
		],
		"name": "isApprovedForAll",
		"outputs": [
			{
				"internalType": "bool",
				"name": "",
				"type": "bool"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "account",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "amount",
				"type": "uint256"
			},
			{
				"internalType": "string",
				"name": "ipfsCID",
				"type": "string"
			}
		],
		"name": "mint",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"internalType": "uint256[]",
				"name": "amounts",
				"type": "uint256[]"
			},
			{
				"internalType": "string[]",
				"name": "ipfsCIDs",
				"type": "string[]"
			}
		],
		"name": "mintBatch",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [],
		"name": "owner",
		"outputs": [
			{
				"internalType": "address",
				"name": "",
				"type": "address"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [],
		"name": "renounceOwnership",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"internalType": "uint256[]",
				"name": "ids",
				"type": "uint256[]"
			},
			{
				"internalType": "uint256[]",
				"name": "values",
				"type": "uint256[]"
			},
			{
				"internalType": "bytes",
				"name": "data",
				"type": "bytes"
			}
		],
		"name": "safeBatchTransferFrom",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "from",
				"type": "address"
			},
			{
				"internalType": "address",
				"name": "to",
				"type": "address"
			},
			{
				"internalType": "uint256",
				"name": "id",
				"type": "uint256"
			},
			{
				"internalType": "uint256",
				"name": "value",
				"type": "uint256"
			},
			{
				"internalType": "bytes",
				"name": "data",
				"type": "bytes"
			}
		],
		"name": "safeTransferFrom",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "operator",
				"type": "address"
			},
			{
				"internalType": "bool",
				"name": "approved",
				"type": "bool"
			}
		],
		"name": "setApprovalForAll",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "string",
				"name": "newuri",
				"type": "string"
			}
		],
		"name": "setURI",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "bytes4",
				"name": "interfaceId",
				"type": "bytes4"
			}
		],
		"name": "supportsInterface",
		"outputs": [
			{
				"internalType": "bool",
				"name": "",
				"type": "bool"
			}
		],
		"stateMutability": "view",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "address",
				"name": "newOwner",
				"type": "address"
			}
		],
		"name": "transferOwnership",
		"outputs": [],
		"stateMutability": "nonpayable",
		"type": "function"
	},
	{
		"inputs": [
			{
				"internalType": "uint256",
				"name": "",
				"type": "uint256"
			}
		],
		"name": "uri",
		"outputs": [
			{
				"internalType": "string",
				"name": "",
				"type": "string"
			}
		],
		"stateMutability": "view",
		"type": "function"
	}
];

// Function to mint an ERC-1155 NFT
async function mintNFTree(to, tokenId, amount, tokenURI) {
  try {
    // Initialize provider and signer
    const provider = new ethers.JsonRpcProvider(RPC_URL);
    const signer = new ethers.Wallet(PRIVATE_KEY, provider);

    // Connect to the ERC-1155 contract
    const erc1155Contract = new ethers.Contract(NFTree_CONTRACT_ADDRESS, NFTree_ABI, signer);

    // Mint the NFT
    console.log(`Minting NFT for ${to}, Token ID: ${tokenId}, Amount: ${amount}, URI: ${tokenURI}`);
    const tx = await erc1155Contract.mint(to, tokenId, amount, tokenURI);

    // Wait for the transaction to be confirmed
    const receipt = await tx.wait();
    console.log("ERC-1155 NFT created successfully! Transaction details:", receipt);

    return receipt;
  } catch (error) {
    console.error("Error minting NFT:", error);
    throw error;
  }
}

module.exports = { mintNFTree };



================================================
File: smart-contracts/uploadToIPFS.js
================================================
// uploadToIPFS.js
require('dotenv').config();
const axios = require('axios');
const FormData = require('form-data');
const fs = require('fs');
const path = require('path');

/**
 * Upload research JSON data to IPFS via Lighthouse.
 * @param {Object} researchData - The research data object to be uploaded.
 * @returns {Promise<string>} - A promise that resolves with the IPFS CID.
 */
async function uploadResearchToIPFS(researchData) {
  const url = 'https://node.lighthouse.storage/api/v0/add?pin=true';
  const formData = new FormData();
  const buffer = Buffer.from(JSON.stringify(researchData));
  formData.append('file', buffer, { filename: 'research.json', contentType: 'application/json' });
  
  const headers = {
    ...formData.getHeaders(),
    'Authorization': `Bearer ${process.env.LIGHTHOUSE_API_KEY}`
  };
  
  try {
    console.log('Uploading research JSON to IPFS via Lighthouse...');
    const response = await axios.post(url, formData, { headers });
    const ipfsCid = response.data.Hash;
    console.log('Received IPFS CID for research JSON:', ipfsCid);
    return ipfsCid;
  } catch (error) {
    console.error('Error uploading research JSON to Lighthouse:', error.response ? error.response.data : error.message);
    throw error;
  }
}

/**
 * Upload attestation metadata (from a file) to IPFS via Lighthouse.
 * @param {string} metadataFilePath - The full path to the metadata file.
 * @returns {Promise<string>} - A promise that resolves with the IPFS CID.
 */
async function uploadMetadataToIPFS(metadataFilePath) {
  const url = 'https://node.lighthouse.storage/api/v0/add?pin=true';
  const formData = new FormData();
  
  // Ensure the file exists before attempting to upload
  if (!fs.existsSync(metadataFilePath)) {
    throw new Error(`File not found: ${metadataFilePath}`);
  }
  
  const fileStream = fs.createReadStream(metadataFilePath);
  formData.append('file', fileStream, { filename: 'attestation_metadata.json', contentType: 'application/json' });
  
  const headers = {
    ...formData.getHeaders(),
    'Authorization': `Bearer ${process.env.LIGHTHOUSE_API_KEY}`
  };
  
  try {
    console.log('Uploading attestation metadata to IPFS via Lighthouse...');
    const response = await axios.post(url, formData, { headers });
    const ipfsCid = response.data.Hash;
    console.log('Received IPFS CID for metadata:', ipfsCid);
    return ipfsCid;
  } catch (error) {
    console.error('Error uploading metadata to Lighthouse:', error.response ? error.response.data : error.message);
    throw error;
  }
}

module.exports = { uploadResearchToIPFS, uploadMetadataToIPFS };



================================================
File: src/eslint.config.mjs
================================================
import { dirname } from "path";
import { fileURLToPath } from "url";
import { FlatCompat } from "@eslint/eslintrc";

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

const compat = new FlatCompat({
  baseDirectory: __dirname,
});

const eslintConfig = [
  ...compat.extends("next/core-web-vitals", "next/typescript"),
];

export default eslintConfig;



================================================
File: src/app/globals.css
================================================
@tailwind base;
@tailwind components;
@tailwind utilities;

body {
  font-family: Arial, Helvetica, sans-serif;
}

@layer base {
  :root {
    --background: 0 0% 100%;
    --foreground: 240 10% 3.9%;
    --card: 0 0% 100%;
    --card-foreground: 240 10% 3.9%;
    --popover: 0 0% 100%;
    --popover-foreground: 240 10% 3.9%;
    --primary: 240 5.9% 10%;
    --primary-foreground: 0 0% 98%;
    --secondary: 240 4.8% 95.9%;
    --secondary-foreground: 240 5.9% 10%;
    --muted: 240 4.8% 95.9%;
    --muted-foreground: 240 3.8% 46.1%;
    --accent: 240 4.8% 95.9%;
    --accent-foreground: 240 5.9% 10%;
    --destructive: 0 84.2% 60.2%;
    --destructive-foreground: 0 0% 98%;
    --border: 240 5.9% 90%;
    --input: 240 5.9% 90%;
    --ring: 240 10% 3.9%;
    --chart-1: 12 76% 61%;
    --chart-2: 173 58% 39%;
    --chart-3: 197 37% 24%;
    --chart-4: 43 74% 66%;
    --chart-5: 27 87% 67%;
    --radius: 0.5rem;
  }
  .dark {
    --background: 240 10% 3.9%;
    --foreground: 0 0% 98%;
    --card: 240 10% 3.9%;
    --card-foreground: 0 0% 98%;
    --popover: 240 10% 3.9%;
    --popover-foreground: 0 0% 98%;
    --primary: 0 0% 98%;
    --primary-foreground: 240 5.9% 10%;
    --secondary: 240 3.7% 15.9%;
    --secondary-foreground: 0 0% 98%;
    --muted: 240 3.7% 15.9%;
    --muted-foreground: 240 5% 64.9%;
    --accent: 240 3.7% 15.9%;
    --accent-foreground: 0 0% 98%;
    --destructive: 0 62.8% 30.6%;
    --destructive-foreground: 0 0% 98%;
    --border: 240 3.7% 15.9%;
    --input: 240 3.7% 15.9%;
    --ring: 240 4.9% 83.9%;
    --chart-1: 220 70% 50%;
    --chart-2: 160 60% 45%;
    --chart-3: 30 80% 55%;
    --chart-4: 280 65% 60%;
    --chart-5: 340 75% 55%;
  }
}

@layer base {
  * {
    @apply border-border;
  }
  body {
    @apply bg-background text-foreground;
  }
}



================================================
File: src/app/layout.tsx
================================================
import type { Metadata } from "next";
import { Montserrat } from "next/font/google";
import "./globals.css";
import { ResearchProvider } from "@/context/research-context";
import Providers from "./providers";
import '@coinbase/onchainkit/styles.css'; 
import SilviLogo from '/public/SilviFaviconNew.svg'
import { Suspense } from "react";


const montserrat = Montserrat({
  variable: "--font-montserrat",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: {
      default: 'Treekipedia',
      template: '%s | Treekipedia'
  },
  viewport: {
      width: 'device-width',
      initialScale: 1
  },
  description: 'Silvi is a reforestation project that uses blockchain technology to incentivize and track the planting of trees.',
  keywords: ['Web3', 'Reforestation', 'Environment', 'Climate Change', 'Base', 'Blockchain', 'Silvi', 'NFT'],
  icons: { icon: SilviLogo.src, shortcut: SilviLogo.src }
}



export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {


  return (
    <html lang="en">
      <body
        className={montserrat.className}
      >
        <Providers>
          <ResearchProvider>
            <Suspense>
              {children}
            </Suspense>

            </ResearchProvider>
        </Providers>
        </body>
    </html>
  );
}



================================================
File: src/app/page.tsx
================================================
import { redirect } from 'next/navigation'

const HomePage = () => {
  redirect('/species')
}

export default HomePage


================================================
File: src/app/providers.tsx
================================================
"use client"

import { QueryClient, QueryClientProvider } from '@tanstack/react-query'
import { ReactQueryDevtools } from '@tanstack/react-query-devtools'
import React from 'react'
import { OnchainKitProvider } from '@coinbase/onchainkit';
import { baseSepolia } from 'wagmi/chains'; // add baseSepolia for testing
import { Toaster } from 'react-hot-toast';



const Providers = ({children}: {children: React.ReactNode}) => {

    const [queryClient] = React.useState(() => new QueryClient({
        defaultOptions: {
          queries: {
            staleTime: 60 * 1000, // 1 minute
            refetchOnWindowFocus: false,
          },
        },
      }))
    
 
  return (
    <OnchainKitProvider apiKey={process.env.NEXT_PUBLIC_ONCHAINKIT_API_KEY} chain={baseSepolia}>
    <QueryClientProvider client={queryClient}>
      {children}
      <ReactQueryDevtools initialIsOpen={false} />
    <Toaster position="top-right" />
    </QueryClientProvider>
    </OnchainKitProvider>
  )
}

export default Providers



================================================
File: src/app/species/page.tsx
================================================
import { SearchForm } from "@/components/search-form";
import { SearchResults } from "@/components/search-results";
import { Navbar } from "@/components/navbar";

export default function SpeciesPage() {
  return (
    <div className="min-h-screen bg-gradient-to-b from-green-100 to-green-200">
      <Navbar />
      <main className="w-full min-h-screen bg-white">
        <div
          className="relative min-h-screen flex flex-col"
          style={{
            backgroundImage:
              "linear-gradient(rgba(0, 0, 0, 0.7), rgba(0, 0, 0, 0.7)), url(https://images.unsplash.com/photo-1542273917363-3b1817f69a2d?auto=format&fit=crop&q=80)",
            backgroundSize: "cover",
            backgroundPosition: "center",
          }}
        >
          <div className="max-w-6xl mx-auto md:pt-16 pt-24 px-4 w-full">
            <h1 className="text-xl md:text-4xl font-bold mb-6 text-white text-center">
              The Open Encyclopedia of Trees
            </h1>
            {/* <p className="text-md md:text-lg mb-8 text-white">
              Discover, explore, and contribute to the world&apos;s largest tree
              database
            </p> */}
            <SearchForm />
          </div>

          <div className="flex-1 mx-auto w-full max-w-6xl px-4 mb-6">
            <h2 className="text-xl font-semibold text-white mb-4 sticky top-0">
              Search Results
            </h2>
            <div className="p-4 rounded-xl bg-white/10 backdrop-blur-md border border-white/20 overflow-auto max-h-[calc(100vh-220px)]">
              <SearchResults />
            </div>
          </div>
        </div>
      </main>
    </div>
  );
}



================================================
File: src/app/species/[id]/page.tsx
================================================
"use client";

import { ResearchTable } from "@/components/research-table";
import { Button } from "@/components/ui/button";
import { ResearchData, ResearchPayload, Species } from "@/lib/types";
import { useQuery, useMutation } from "@tanstack/react-query";
import axios from "axios";
import { ArrowLeft } from "lucide-react";
import { useRouter, useParams } from "next/navigation";
import React from "react";
import { useAccount } from "wagmi";
import { toast } from "react-hot-toast";

const SpeciesDetailsPage = () => {
  const params = useParams();
  const router = useRouter();
  const speciesId = params.id;
  console.log(speciesId);
  const { address } = useAccount();
  console.log("address", address);
  const {
    data: species,
    isLoading,
    isError,
  } = useQuery<Species>({
    queryKey: ["species", speciesId],
    queryFn: async () => {
      if (!speciesId) throw new Error("No species ID provided");
      const { data } = await axios.get(
        `https://silviapi.herokuapp.com/core/species/${speciesId}`
      );
      return data;
    },
    enabled: !!speciesId, // Only run query if speciesId exists
  });

  const {
    data: researchData,
    isLoading: isResearchLoading,
    refetch: refetchResearch,
  } = useQuery<ResearchData>({
    queryKey: ["research", species?.species_scientific_name],
    queryFn: async () => {
      if (!species?.species_scientific_name)
        throw new Error("No scientific name available");
      const { data } = await axios.get(
        `http://64.227.23.153:3000/ai/research/${species?.species_scientific_name}`
      );
      return data;
    },
    enabled: !!species?.species_scientific_name,
  });

  console.log("Research data:", researchData);

  const researchMutation = useMutation({
    mutationFn: async (payload: ResearchPayload) => {
      console.log("Sending research payload:", payload);
      const response = await axios.post(
        "http://64.227.23.153:3000/ai/research",
        payload
      );
      console.log("Research response:", response.data);
      return response.data;
    },
    onSuccess: (data) => {
      console.log("Research mutation successful:", data);
      // Refetch research data after successful mutation
      refetchResearch();
    },
    onError: (error) => {
      if (axios.isAxiosError(error)) {
        if (error.code === "ERR_NETWORK") {
          toast.error("Network Error: An unexpected network error occurred.");
        } else {
          toast.error("Research Failed: An unexpected error occurred.");
        }
      } else {
        toast.error("Research Failed: An unexpected error occurred.");
      }
    },
  });

  const handleResearch = () => {
    if (!species) return;

    const payload = {
      scientificName: species.species_scientific_name,
      commonNames: [species.species_common_name],
      researcherWallet: address!,
    };

    console.log("Initiating research with payload:", payload);
    researchMutation.mutate(payload);
  };

  if (isLoading) {
    return (
      <div className="container mx-auto px-4 py-8 bg-gray-100">
        <div className="rounded-xl bg-gray-100 p-8 shadow-[inset_-12px_-12px_24px_#ffffff,inset_12px_12px_24px_#d1d1d1]">
          <div className="h-8 bg-gray-200 rounded-xl w-1/3 mb-6 shadow-[5px_5px_10px_#d1d1d1,-5px_-5px_10px_#ffffff]"></div>
          <div className="grid grid-cols-1 md:grid-cols-2 gap-6">
            {[...Array(6)].map((_, i) => (
              <div
                key={i}
                className="h-4 bg-gray-200 rounded-xl w-3/4 shadow-[5px_5px_10px_#d1d1d1,-5px_-5px_10px_#ffffff]"
              ></div>
            ))}
          </div>
        </div>
      </div>
    );
  }

  if (isError) {
    return (
      <div className="container mx-auto px-4 py-8">
        <div className="bg-white rounded-lg shadow-lg p-6 text-center">
          <h2 className="text-2xl font-bold mb-4">
            Error loading species data
          </h2>
          <Button
            onClick={() => router.back()}
            className="bg-green-800 hover:bg-green-700"
          >
            Go Back
          </Button>
        </div>
      </div>
    );
  }

  if (!species) {
    return (
      <div className="container mx-auto px-4 py-8">
        <div className="bg-white rounded-lg shadow-lg p-6 text-center">
          <h2 className="text-2xl font-bold mb-4">Species not found</h2>
          <Button
            onClick={() => router.back()}
            className="bg-green-800 hover:bg-green-700"
          >
            Go Back
          </Button>
        </div>
      </div>
    );
  }
  return (
    <div className="min-h-screen bg-gray-100">
      <div className="max-w-7xl w-full mx-auto px-4 py-2">
        <div className="flex items-center gap-2 py-4 ">
          <Button
            onClick={() => router.back()}
            variant="outline"
            className="flex items-center gap-2 px-6 py-3 rounded-xl bg-gray-100 text-black 
            shadow-[5px_5px_10px_#d1d1d1,-5px_-5px_10px_#ffffff] 
            hover:shadow-[inset_5px_5px_10px_#d1d1d1,inset_-5px_-5px_10px_#ffffff] 
            transition-all duration-300"
          >
            <ArrowLeft className="w-6 h-6" />
            Back to Search
          </Button>
        </div>

        <div
          className="rounded-xl bg-gray-100 p-8 
          shadow-[12px_12px_24px_#d1d1d1,-12px_-12px_24px_#ffffff]"
        >
          <div className="grid grid-cols-1 md:grid-cols-2 gap-8">
            <div
              className="p-6 rounded-xl bg-gray-100 
              shadow-[inset_8px_8px_16px_#d1d1d1,inset_-8px_-8px_16px_#ffffff]"
            >
              <div className="mb-8">
                <h1 className="text-4xl font-bold mb-2 text-gray-800">
                  {species.species_scientific_name}
                </h1>
                <p className="text-2xl text-gray-600">
                  {species.species_common_name}
                </p>
              </div>

              <div className="flex gap-4 mb-8">
                <Button
                  variant="primary"
                  className="px-6 py-3 rounded-xl bg-green-600 
                  shadow-[5px_5px_10px_#d1d1d1,-5px_-5px_10px_#ffffff] 
                  hover:shadow-[inset_5px_5px_10px_#1b4332,inset_-5px_-5px_10px_#2d6a4f] 
                  transition-all duration-300"
                  onClick={handleResearch}
                  disabled={researchMutation.isPending}
                >
                  {researchMutation.isPending ? "Researching..." : "Research"}
                </Button>
                <Button
                  variant="primary"
                  className="px-6 py-3 rounded-xl bg-gray-200 text-black
                  shadow-[5px_5px_10px_#d1d1d1,-5px_-5px_10px_#ffffff] 
                  hover:shadow-[inset_5px_5px_10px_#d1d1d1,inset_-5px_-5px_10px_#ffffff] 
                  transition-all duration-300"
                  disabled={researchMutation.isPending}
                  onClick={() => router.push(`/species/${speciesId}/nfts`)}
                >
                  View my NFTs
                </Button>
              </div>

              <div
                className="p-6 rounded-xl bg-gray-100 
                shadow-[inset_8px_8px_16px_#d1d1d1,inset_-8px_-8px_16px_#ffffff]"
              >
                <h2 className="text-xl font-semibold mb-4 text-gray-800">
                  Taxonomy
                </h2>
                <div className="space-y-4">
                  <p
                    className="flex justify-between items-center p-3 rounded-lg bg-gray-100 
                    shadow-[3px_3px_6px_#d1d1d1,-3px_-3px_6px_#ffffff]"
                  >
                    <span className="font-medium">Family:</span>
                    <span>{species.family}</span>
                  </p>
                  <p
                    className="flex justify-between items-center p-3 rounded-lg bg-gray-100 
                    shadow-[3px_3px_6px_#d1d1d1,-3px_-3px_6px_#ffffff]"
                  >
                    <span className="font-medium">Genus:</span>
                    <span>{species.genus}</span>
                  </p>
                  {species.subspecies && (
                    <p
                      className="flex justify-between items-center gap-2 p-3 rounded-lg bg-gray-100 
                      shadow-[3px_3px_6px_#d1d1d1,-3px_-3px_6px_#ffffff]"
                    >
                      <span className="font-medium">Subspecies:</span>
                      <span>{species.subspecies}</span>
                    </p>
                  )}
                  <p
                    className="flex justify-between items-center p-3 rounded-lg bg-gray-100 
                    shadow-[3px_3px_6px_#d1d1d1,-3px_-3px_6px_#ffffff]"
                  >
                    <span className="font-medium">Class:</span>
                    <span>{species.taxonomic_class}</span>
                  </p>
                  <p
                    className="flex justify-between items-center p-3 rounded-lg bg-gray-100 
                    shadow-[3px_3px_6px_#d1d1d1,-3px_-3px_6px_#ffffff]"
                  >
                    <span className="font-medium">Order:</span>
                    <span>{species.taxonomic_order}</span>
                  </p>
                </div>

                <div className="mt-8">
                  <div className="">
                    <h2 className="text-xl font-semibold mb-4 text-gray-800">
                      General Description
                    </h2>
                    <div
                      className="p-4 rounded-lg bg-gray-100 
                      shadow-[3px_3px_6px_#d1d1d1,-3px_-3px_6px_#ffffff]"
                    >
                      <p className="text-gray-700 leading-relaxed">
                        {researchData?.general_description ||
                          "This species is currently being researched. Description will be available soon."}
                      </p>
                    </div>
                  </div>
                </div>
              </div>
            </div>

            <div
              className="p-6 rounded-xl bg-gray-100 
              shadow-[inset_8px_8px_16px_#d1d1d1,inset_-8px_-8px_16px_#ffffff]"
            >
              <ResearchTable
                data={researchData}
                isLoading={isResearchLoading}
                researchMutation={researchMutation}
              />
            </div>
          </div>
        </div>
      </div>
    </div>
  );
};

export default SpeciesDetailsPage;



================================================
File: src/app/species/[id]/nfts/page.tsx
================================================
"use client";

import { Button } from "@/components/ui/button";
import { useAccount } from "wagmi";
import { useRouter } from "next/navigation";
import { ArrowLeft, Loader2 } from "lucide-react";
import { Network, Alchemy } from "alchemy-sdk";
import { useEffect, useState } from "react";
import Image from "next/image";

const NFT_CONTRACT_ADDRESS = "0x5Ed6240fCC0B2A231887024321Cc9481ba07f3c6";

// Configure Alchemy SDK
const alchemy = new Alchemy({
  apiKey: process.env.NEXT_PUBLIC_ALCHEMY_API_KEY,
  network: Network.BASE_SEPOLIA,
});

// NFT Card Component

// eslint-disable-next-line @typescript-eslint/no-explicit-any
function NFTCard({ nft }: { nft: any }) {
  return (
    <div className="rounded-xl bg-gray-100 p-2 transform transition-all duration-300 hover:-translate-y-2
    shadow-[8px_8px_15px_#d1d1d1,-8px_-8px_15px_#ffffff]
    hover:shadow-[12px_12px_20px_#d1d1d1,-12px_-12px_20px_#ffffff]">
      <div className="relative w-full h-48 rounded-lg overflow-hidden">
        {nft.image ? (
          <Image
            src={nft.image}
            alt={nft.title || "NFT"}
            fill
            className="object-cover"
          />
        ) : (
          <div className="w-full h-full bg-gray-200 flex items-center justify-center rounded-lg">
            No Image
          </div>
        )}
      </div>
      <div className="p-4">
        <h3 className="font-semibold text-lg mb-2 text-gray-800">
          {nft.title || `Token ID: ${nft.tokenId}`}
        </h3>
        {nft.description && (
          <p className="text-sm text-gray-600 line-clamp-2">{nft.description}</p>
        )}
        <div className="mt-2 text-sm text-gray-700">
          Quantity: {nft.balance}
        </div>
      </div>
    </div>
  );
}

export default function NFTsPage() {
  const { address } = useAccount();
  const router = useRouter();
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  const [nfts, setNfts] = useState<any[]>([]);
  const [loading, setLoading] = useState(true);
  console.log("nfts", nfts);

  useEffect(() => {
    async function fetchNFTs() {
      if (!address) {
        setLoading(false);
        return;
      }

      try {
        const response = await alchemy.nft.getNftsForOwner(
            address,
            {
              contractAddresses: [NFT_CONTRACT_ADDRESS],
              omitMetadata: false,
            }
          );

        // Transform the NFT data
        const nftData = await Promise.all(
          response.ownedNfts.map(async (nft) => {
            const metadata = nft?.raw.metadata;
            let image = metadata?.image || '';
            
            if (image.startsWith('ipfs://')) {
              image = image.replace('ipfs://', 'https://ipfs.io/ipfs/');
            }

            return {
              tokenId: nft.tokenId,
              title: metadata?.name || `NFT #${nft.tokenId}`,
              description: metadata?.description,
              image: image,
              // Add balance information since ERC1155 tokens can have multiple copies
              balance: nft.balance,
            };
          })
        );

        console.log("Fetched NFT data:", nftData);
        setNfts(nftData);
      } catch (error) {
        console.error("Error fetching NFTs:", error);
      } finally {
        setLoading(false);
      }
    }

    fetchNFTs();
  }, [address]);

  if (loading) {
    return (
      <div className="min-h-screen bg-gray-100">
        <div className="max-w-7xl mx-auto px-4 py-8">
          <div className="flex flex-col space-y-2 items-center justify-center gap-2 p-8 rounded-xl" style={{
            boxShadow: 'inset 5px 5px 10px #d1d1d1, inset -5px -5px 10px #ffffff'
          }}>
            <Loader2 className="w-10 h-10 animate-spin text-green-500" />
            Loading NFTs...
          </div>
        </div>
      </div>
    );
  }

  return (
    <div className="min-h-screen bg-gray-100">
      <div className="max-w-7xl mx-auto px-4 py-8">
        <div className="mb-8">
          <Button
            onClick={() => router.back()}
            variant="outline"
            className="flex items-center gap-2 px-6 py-3 rounded-xl bg-gray-100 text-black 
            shadow-[5px_5px_10px_#d1d1d1,-5px_-5px_10px_#ffffff] 
            hover:shadow-[inset_5px_5px_10px_#d1d1d1,inset_-5px_-5px_10px_#ffffff] 
            transition-all duration-300"
          >
            <ArrowLeft className="w-4 h-4" />
            Back to Species
          </Button>
        </div>

        <div className="rounded-xl p-8 bg-gray-100" style={{
          boxShadow: '10px 10px 20px #d1d1d1, -10px -10px 20px #ffffff'
        }}>
          <h1 className="text-2xl font-bold mb-6 text-gray-800">Your Research NFTs</h1>
          
          {!address ? (
            <div className="text-center py-8 rounded-xl bg-gray-100" style={{
              boxShadow: 'inset 5px 5px 10px #d1d1d1, inset -5px -5px 10px #ffffff'
            }}>
              Please connect your wallet to view NFTs
            </div>
          ) : nfts.length === 0 ? (
            <div className="text-center py-8 rounded-xl bg-gray-100" style={{
              boxShadow: 'inset 5px 5px 10px #d1d1d1, inset -5px -5px 10px #ffffff'
            }}>
              No Research NFTs found in your wallet
            </div>
          ) : (
            <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-8">
              {nfts.map((nft) => (
                <NFTCard key={nft.tokenId} nft={nft} />
              ))}
            </div>
          )}
        </div>
      </div>
    </div>
  );
}



================================================
File: src/components/navbar.tsx
================================================
"use client"

import Image from "next/image"
import Link from "next/link"
import {
  ConnectWallet,
  Wallet,
  WalletDropdown,
  WalletDropdownLink,
  WalletDropdownDisconnect,
} from '@coinbase/onchainkit/wallet';
import {
  Address,
  Avatar,
  Name,
  Identity,
  EthBalance,
} from '@coinbase/onchainkit/identity';

export function Navbar() {
  

  return (
    <nav className="fixed top-0 left-0 right-0 z-50">
      <div className="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
        <div className="flex justify-between items-center h-16">
          <Link href="/" className="flex items-center">
            <Image
              src="/silvi_logo.png" // Make sure to add your logo file to the public directory
              alt="Logo"
              width={100}
              height={100}
              className=""
            />
          </Link>
          
          <div className="wallet-container">
            <Wallet>
              <ConnectWallet className='bg-white text-black hover:bg-white hover:text-black'>
                <Avatar className="h-6 w-6 text-black" />
                <Name className="text-black" />
              </ConnectWallet>
              <WalletDropdown>
                <Identity className="px-4 pt-3 pb-2" hasCopyAddressOnClick>
                  <Avatar />
                  <Name />
                  <Address />
                  <EthBalance />
                </Identity>
                <WalletDropdownLink
                  icon="wallet"
                  href="https://keys.coinbase.com"
                  target="_blank"
                  rel="noopener noreferrer"
                >
                  Wallet
                </WalletDropdownLink>
                <WalletDropdownLink
                  icon="wallet"
                  href="https://t.me/SilviProtocol/1"
                  target="_blank"
                  rel="noopener noreferrer"
                >
                  Silvi Telegram
                </WalletDropdownLink>
                <WalletDropdownDisconnect />
              </WalletDropdown>
            </Wallet>
          </div>
        </div>
      </div>
    </nav>
  )
} 


================================================
File: src/components/research-table.tsx
================================================
"use client";

import {
  Table,
  TableBody,
  TableCell,
  TableHead,
  TableHeader,
  TableRow,
} from "@/components/ui/table";
import { ResearchData, ResearchPayload } from "@/lib/types";
import { UseMutationResult } from "@tanstack/react-query";
import { Loader2 } from "lucide-react";

const tableMapping = [
  { label: "Native/Adapted Habitats", key: "native_adapted_habitats" },
  { label: "Stewardship Best Practices", key: "stewardship_best_practices" },
  { label: "Planting Methods", key: "planting_methods" },
  { label: "Ecological Function", key: "ecological_function" },
  { label: "Agroforestry Use Cases", key: "agroforestry_use_cases" },
  { label: "Elevation Ranges", key: "elevation_ranges" },
  { label: "Compatible Soil Types", key: "compatible_soil_types" },
  { label: "Conservation Status", key: "conservation_status" },
  { label: "Research Status", key: "research_status" },
];

interface ResearchTableProps {
  data?: ResearchData;
  isLoading: boolean;
  researchMutation: UseMutationResult<ResearchData, Error, ResearchPayload>;
}

export const ResearchTable: React.FC<ResearchTableProps> = ({
  data,
  isLoading,
  researchMutation,
}) => {
  if (isLoading) {
    return (
      <div className="h-full flex items-center justify-center">
        Loading research data...
      </div>
    );
  }

  if (researchMutation.isPending) {
    return (
      <div className="h-full flex flex-col gap-4 items-center justify-center">
        <Loader2 className="w-10 h-10 animate-spin text-green-800" />
        AI Agent Researching...
      </div>
    );
  }

  if (!data) {
    return (
      <div className="h-full flex items-center justify-center">
        No research data available
        <br />
        (Click research button to generate research data)
      </div>
    );
  }

  return (
    <div className="h-full p-4 flex flex-col bg-white rounded-xl">
      <h2 className="text-xl font-semibold mb-4">Research: {data.taxon_id}</h2>
      <div className="flex-1 overflow-auto">
        <Table className="border rounded-lg">
          <TableHeader>
            <TableRow>
              <TableHead className="w-1/3">Attribute</TableHead>
              <TableHead>Information</TableHead>
            </TableRow>
          </TableHeader>
          <TableBody>
            {tableMapping.map((item) => (
              <TableRow key={item.key}>
                <TableCell className="font-medium">{item.label}</TableCell>
                <TableCell className="whitespace-pre-wrap">
                  {data[item.key as keyof ResearchData] || "Data not available"}
                </TableCell>
              </TableRow>
            ))}
          </TableBody>
        </Table>
      </div>
    </div>
  );
};



================================================
File: src/components/search-form.tsx
================================================
"use client";

import { useState, useEffect } from "react";
import { useRouter, useSearchParams } from "next/navigation";
import { Search } from "lucide-react";
import { useAccount } from 'wagmi';
import { toast } from "sonner";

export function SearchForm() {
  const router = useRouter();
  const searchParams = useSearchParams();
  const [query, setQuery] = useState(searchParams.get("q") || "");
  const { address } = useAccount();

  useEffect(() => {
    const delayDebounceFn = setTimeout(() => {
      if (query.trim()) {
        if (!address) {
          toast.error("Please connect your wallet to search");
          return;
        }
        router.push(`/species?q=${encodeURIComponent(query.trim())}`);
      } else {
        router.push('/species');
      }
    }, 300);
  
    return () => clearTimeout(delayDebounceFn);
  }, [query, router, address]);

  const handleSubmit = (e: React.FormEvent) => {
    e.preventDefault();
    if (!address) {
      toast.error("Please connect your wallet to search");
      return;
    }
    if (query.trim()) {
      router.push(`/species?q=${encodeURIComponent(query.trim())}`);
    } else {
      router.push('/species');
    }
  };

  return (
    <div className="relative z-10 mb-8">
      <form onSubmit={handleSubmit} className="flex gap-2">
        <div className="max-w-2xl mx-auto w-full relative">
          <div className="relative">
            <input
              type="text"
              placeholder={address ? "Search for any tree species..." : "Connect wallet to search..."}
              value={query}
              onChange={(e) => setQuery(e.target.value)}
              className="w-full flex-grow px-6 py-4 rounded-xl bg-white/10 backdrop-blur-md border border-white/20 text-white placeholder-white/70 focus:ring-2 focus:ring-green-500 focus:border-transparent outline-none"
              disabled={!address}
            />
            <button 
              type="submit"
              disabled={!address}
            >
              <Search className="absolute right-4 top-1/2 -translate-y-1/2 text-white/70 w-6 h-6" />
            </button>
          </div>
        </div>
      </form>
    </div>
  );
}



================================================
File: src/components/search-results.tsx
================================================
"use client";

import { useSearchParams } from "next/navigation";
import { useQuery } from "@tanstack/react-query";
import { searchTreeSpecies } from "@/lib/api";
import Link from "next/link";
import { useAccount } from "wagmi";
import { Loader2 } from "lucide-react";

export function SearchResults() {
  const searchParams = useSearchParams();
  const query = searchParams.get("q");
  const { address } = useAccount();

  const { data: results = [], isLoading } = useQuery({
    queryKey: ["trees", query],
    queryFn: () => searchTreeSpecies(query || ""),
    enabled: !!query && !!address,
  });

  if (!address) {
    return (
      <div className="h-full flex items-center justify-center p-8">
        <div className="text-center p-8 rounded-xl">
          <h3 className="text-lg font-semibold text-green-500 mb-2">
            Connect Your Wallet
          </h3>
          <p className="text-white">
            Please connect your wallet to start searching for tree species.
          </p>
        </div>
      </div>
    );
  }

  if (!query) {
    return (
      <div className="h-full flex items-center justify-center p-8">
        <div className="text-center p-8 rounded-xl">
          <h3 className="text-lg font-semibold text-green-500 mb-2">
            Start Your Tree Research
          </h3>
          <p className="text-white">
            Enter a tree species name in the search box above to discover
            detailed information about different trees.
          </p>
        </div>
      </div>
    );
  }

  if (isLoading) {
    return (
      <div className="h-full flex items-center justify-center flex-col gap-4">
        <Loader2 className="w-10 h-10 animate-spin text-green-500" />
        <p className=" text-white p-4 rounded-xl ">Searching...</p>
      </div>
    );
  }

  if (results.length === 0) {
    return (
      <div className="h-full flex items-center justify-center p-8">
        <div className="text-center p-8 rounded-xl bg-white shadow-[inset_-12px_-12px_24px_rgba(0,0,0,0.1),_inset_12px_12px_24px_rgba(255,255,255,0.5)]">
          <h3 className="text-lg font-semibold text-gray-800 mb-2">
            No Results Found
          </h3>
          <p className="text-gray-600">
            We couldn&apos;t find any tree species matching {`${query}`}. Try
            searching with a different name or check your spelling.
          </p>
        </div>
      </div>
    );
  }

  return (
    <div className="h-full flex flex-col p-6">
      <div className="flex-1 overflow-auto grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-6">
        {results.map((tree) => (
          <Link
            key={tree.id}
            href={`/species/${tree.id}`}
            className="bg-white p-6 rounded-xl transition-all duration-300
              "
          >
            <h2 className="text-xl font-semibold text-gray-800">
              {tree.species_common_name}
            </h2>
            <p className="text-gray-600 italic">
              {tree.species_scientific_name}
            </p>
            <ul className="mt-4 space-y-2">
              <li className="text-gray-700">
                <span className="font-medium text-gray-900">Family:</span>{" "}
                {tree.family}
              </li>
              <li className="text-gray-700">
                <span className="font-medium text-gray-900">Genus:</span>{" "}
                {tree.genus}
              </li>
              <li className="text-gray-700">
                <span className="font-medium text-gray-900">Subspecies:</span>{" "}
                {tree.subspecies || "N/A"}
              </li>
              <li className="text-gray-700">
                <span className="font-medium text-gray-900">Class:</span>{" "}
                {tree.taxonomic_class}
              </li>
              <li className="text-gray-700">
                <span className="font-medium text-gray-900">Order:</span>{" "}
                {tree.taxonomic_order}
              </li>
            </ul>
          </Link>
        ))}
      </div>
    </div>
  );
}



================================================
File: src/components/ui/button.tsx
================================================
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground shadow-sm hover:bg-destructive/90",
        outline:
          "border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground shadow-sm",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
        primary: "bg-green-800 text-white",
      },
      size: {
        default: "h-9 px-4 py-2",
        sm: "h-8 rounded-md px-3 text-xs",
        lg: "h-10 rounded-md px-8",
        icon: "h-9 w-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }



================================================
File: src/components/ui/input.tsx
================================================
import * as React from "react"

import { cn } from "@/lib/utils"

const Input = React.forwardRef<HTMLInputElement, React.ComponentProps<"input">>(
  ({ className, type, ...props }, ref) => {
    return (
      <input
        type={type}
        className={cn(
          "flex h-9 w-full rounded-md border border-input bg-transparent px-3 py-1 text-base shadow-sm transition-colors file:border-0 file:bg-transparent file:text-sm file:font-medium file:text-foreground placeholder:text-muted-foreground focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:cursor-not-allowed disabled:opacity-50 md:text-sm",
          className
        )}
        ref={ref}
        {...props}
      />
    )
  }
)
Input.displayName = "Input"

export { Input }



================================================
File: src/components/ui/sonner.tsx
================================================
"use client"

import { useTheme } from "next-themes"
import { Toaster as Sonner } from "sonner"

type ToasterProps = React.ComponentProps<typeof Sonner>

const Toaster = ({ ...props }: ToasterProps) => {
  const { theme = "system" } = useTheme()

  return (
    <Sonner
      theme={theme as ToasterProps["theme"]}
      className="toaster group"
      toastOptions={{
        classNames: {
          toast:
            "group toast group-[.toaster]:bg-background group-[.toaster]:text-foreground group-[.toaster]:border-border group-[.toaster]:shadow-lg",
          description: "group-[.toast]:text-muted-foreground",
          actionButton:
            "group-[.toast]:bg-primary group-[.toast]:text-primary-foreground",
          cancelButton:
            "group-[.toast]:bg-muted group-[.toast]:text-muted-foreground",
        },
      }}
      {...props}
    />
  )
}

export { Toaster }



================================================
File: src/components/ui/table.tsx
================================================
import * as React from "react"

import { cn } from "@/lib/utils"

const Table = React.forwardRef<
  HTMLTableElement,
  React.HTMLAttributes<HTMLTableElement>
>(({ className, ...props }, ref) => (
  <div className="relative w-full overflow-auto">
    <table
      ref={ref}
      className={cn("w-full caption-bottom text-sm", className)}
      {...props}
    />
  </div>
))
Table.displayName = "Table"

const TableHeader = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <thead ref={ref} className={cn("[&_tr]:border-b", className)} {...props} />
))
TableHeader.displayName = "TableHeader"

const TableBody = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <tbody
    ref={ref}
    className={cn("[&_tr:last-child]:border-0", className)}
    {...props}
  />
))
TableBody.displayName = "TableBody"

const TableFooter = React.forwardRef<
  HTMLTableSectionElement,
  React.HTMLAttributes<HTMLTableSectionElement>
>(({ className, ...props }, ref) => (
  <tfoot
    ref={ref}
    className={cn(
      "border-t bg-muted/50 font-medium [&>tr]:last:border-b-0",
      className
    )}
    {...props}
  />
))
TableFooter.displayName = "TableFooter"

const TableRow = React.forwardRef<
  HTMLTableRowElement,
  React.HTMLAttributes<HTMLTableRowElement>
>(({ className, ...props }, ref) => (
  <tr
    ref={ref}
    className={cn(
      "border-b transition-colors hover:bg-muted/50 data-[state=selected]:bg-muted",
      className
    )}
    {...props}
  />
))
TableRow.displayName = "TableRow"

const TableHead = React.forwardRef<
  HTMLTableCellElement,
  React.ThHTMLAttributes<HTMLTableCellElement>
>(({ className, ...props }, ref) => (
  <th
    ref={ref}
    className={cn(
      "h-10 px-2 text-left align-middle font-medium text-muted-foreground [&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]",
      className
    )}
    {...props}
  />
))
TableHead.displayName = "TableHead"

const TableCell = React.forwardRef<
  HTMLTableCellElement,
  React.TdHTMLAttributes<HTMLTableCellElement>
>(({ className, ...props }, ref) => (
  <td
    ref={ref}
    className={cn(
      "p-2 align-middle [&:has([role=checkbox])]:pr-0 [&>[role=checkbox]]:translate-y-[2px]",
      className
    )}
    {...props}
  />
))
TableCell.displayName = "TableCell"

const TableCaption = React.forwardRef<
  HTMLTableCaptionElement,
  React.HTMLAttributes<HTMLTableCaptionElement>
>(({ className, ...props }, ref) => (
  <caption
    ref={ref}
    className={cn("mt-4 text-sm text-muted-foreground", className)}
    {...props}
  />
))
TableCaption.displayName = "TableCaption"

export {
  Table,
  TableHeader,
  TableBody,
  TableFooter,
  TableHead,
  TableRow,
  TableCell,
  TableCaption,
}



================================================
File: src/context/research-context.tsx
================================================
"use client"

import type React from "react"
import { createContext, useContext, useState } from "react"
import type { TreeSpecies } from "@/lib/types"

interface ResearchContextType {
  selectedSpecies: TreeSpecies | null
  setSelectedSpecies: (species: TreeSpecies | null) => void
}

const ResearchContext = createContext<ResearchContextType | undefined>(undefined)

export function ResearchProvider({ children }: { children: React.ReactNode }) {
  const [selectedSpecies, setSelectedSpecies] = useState<TreeSpecies | null>(null)

  return <ResearchContext.Provider value={{ selectedSpecies, setSelectedSpecies }}>{children}</ResearchContext.Provider>
}

export function useResearchContext() {
  const context = useContext(ResearchContext)
  if (context === undefined) {
    throw new Error("useResearchContext must be used within a ResearchProvider")
  }
  return context
}




================================================
File: src/lib/api.ts
================================================
import axios from 'axios';

export interface APITreeSpecies {
  id: number;
  species_common_name: string;
  species_scientific_name: string;
  subspecies: string | null;
  genus: string;
  family: string;
  taxonomic_class: string;
  taxonomic_order: string;
}

export const searchTreeSpecies = async (query: string): Promise<APITreeSpecies[]> => {
  const { data } = await axios.get(`https://silviapi.herokuapp.com/core/species/?search=${query}`);
  return data;
};


================================================
File: src/lib/search-trees.ts
================================================
export interface TreeSpecies {
  id: number
  commonName: string
  scientificName: string
  family: string
  genus: string
  subspecies: string | null
  class: string
  order: string
  bestPractices: string
  commonCountries: string
  ecoregions: string
  bioregions: string
  biome: string
  ecologicalFunctions: string
  elevationRanges: string
  soilTypes: string
  conservationStatus: string
}

const treeData: TreeSpecies[] = [
  {
    id: 1,
    commonName: "Red Maple",
    scientificName: "Acer rubrum",
    family: "Sapindaceae",
    genus: "Acer",
    subspecies: null,
    class: "Magnoliopsida",
    order: "Sapindales",
    bestPractices: "Regular pruning, protect from wind damage",
    commonCountries: "USA, Canada",
    ecoregions: "Eastern North American forests",
    bioregions: "Temperate broadleaf and mixed forests",
    biome: "Temperate deciduous forest",
    ecologicalFunctions: "Provides habitat for wildlife, soil stabilization",
    elevationRanges: "0-900m",
    soilTypes: "Acidic, moist, well-drained",
    conservationStatus: "Least Concern",
  },
  {
    id: 2,
    commonName: "White Oak",
    scientificName: "Quercus alba",
    family: "Fagaceae",
    genus: "Quercus",
    subspecies: null,
    class: "Magnoliopsida",
    order: "Fagales",
    bestPractices: "Avoid overwatering, protect from pests",
    commonCountries: "USA, Canada, Europe",
    ecoregions: "Eastern North American forests, Western European forests",
    bioregions: "Temperate broadleaf and mixed forests",
    biome: "Temperate deciduous forest",
    ecologicalFunctions: "Provides habitat for wildlife, soil stabilization",
    elevationRanges: "0-1500m",
    soilTypes: "Well-drained, slightly acidic",
    conservationStatus: "Least Concern",
  },
  {
    id: 3,
    commonName: "Douglas Fir",
    scientificName: "Pseudotsuga menziesii",
    family: "Pinaceae",
    genus: "Pseudotsuga",
    subspecies: "menziesii",
    class: "Pinopsida",
    order: "Pinales",
    bestPractices: "Regular pruning, protect from fire",
    commonCountries: "USA, Canada",
    ecoregions: "Pacific Northwest forests",
    bioregions: "Temperate coniferous forests",
    biome: "Temperate coniferous forest",
    ecologicalFunctions: "Provides habitat for wildlife, timber production",
    elevationRanges: "0-3000m",
    soilTypes: "Well-drained, slightly acidic",
    conservationStatus: "Least Concern",
  },
  {
    id: 4,
    commonName: "Giant Sequoia",
    scientificName: "Sequoiadendron giganteum",
    family: "Cupressaceae",
    genus: "Sequoiadendron",
    subspecies: null,
    class: "Pinopsida",
    order: "Pinales",
    bestPractices: "Protect from fire, avoid overwatering",
    commonCountries: "USA",
    ecoregions: "Sierra Nevada forests",
    bioregions: "Temperate coniferous forests",
    biome: "Temperate coniferous forest",
    ecologicalFunctions: "Provides habitat for wildlife, carbon sequestration",
    elevationRanges: "1500-2500m",
    soilTypes: "Well-drained, slightly acidic",
    conservationStatus: "Least Concern",
  },
  {
    id: 5,
    commonName: "Sugar Maple",
    scientificName: "Acer saccharum",
    family: "Sapindaceae",
    genus: "Acer",
    subspecies: null,
    class: "Magnoliopsida",
    order: "Sapindales",
    bestPractices: "Regular pruning, protect from pests",
    commonCountries: "USA, Canada",
    ecoregions: "Eastern North American forests",
    bioregions: "Temperate broadleaf and mixed forests",
    biome: "Temperate deciduous forest",
    ecologicalFunctions: "Provides habitat for wildlife, maple syrup production",
    elevationRanges: "0-1500m",
    soilTypes: "Well-drained, slightly acidic",
    conservationStatus: "Least Concern",
  },
]

export async function searchTrees(query: string): Promise<TreeSpecies[]> {
  // Simulate API delay
  await new Promise((resolve) => setTimeout(resolve, 200))

  return treeData.filter(
    (tree) =>
      tree.commonName.toLowerCase().includes(query.toLowerCase()) ||
      tree.scientificName.toLowerCase().includes(query.toLowerCase()),
  )
}




================================================
File: src/lib/types.ts
================================================
export interface TreeSpecies {
  id: number
  commonName: string
  scientificName: string
  family: string
  genus: string
  subspecies: string | null
  class: string
  order: string
  bestPractices?: string
  commonCountries?: string
  ecoregions?: string
  bioregions?: string
  biome?: string
  ecologicalFunctions?: string
  elevationRanges?: string
  soilTypes?: string
  conservationStatus?: string
}


export interface Species {
  id: string;
  species_common_name: string;
  species_scientific_name: string;
  family: string;
  genus: string;
  subspecies?: string;
  taxonomic_class: string;
  taxonomic_order: string;
  description?: string;
  // Add other fields from your API response
}

export interface ResearchPayload {
  scientificName: string;
  commonNames: string[];
  researcherWallet: string;
}


export interface ResearchData {
  taxon_id: string;
  general_description: string;
  native_adapted_habitats: string;
  stewardship_best_practices: string;
  planting_methods: string;
  ecological_function: string;
  agroforestry_use_cases: string;
  elevation_ranges: string;
  compatible_soil_types: string;
  conservation_status: string;
  research_status: string;
  created_at: string;
  updated_at: string;
  revision: number;
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  revision_history: any[];
  ipfs_cid: string;
  researcher_wallet: string;
}


================================================
File: src/lib/utils.ts
================================================
import { clsx, type ClassValue } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}


