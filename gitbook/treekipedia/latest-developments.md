---
description: 'Current Stage: 2024 Q3 - Data Collection and Cleaning'
---

# Latest Developments

TreeKipedia is currently in the Data Collection and Cleaning phase. We have gathered over 12,000,000 occurrences of tree species data from global sources such as GBIF (Global Biodiversity Information Facility), iNaturalist, idigbio, and National History Museums. Our team is actively working on cleaning this data to ensure its accuracy by removing duplicates, correcting errors, and standardizing formats.\


### **Key Activities in This Stage:**

**Data Cleaning:** Ensuring all collected data is accurate and consistent. This involves removing duplicate records, correcting errors, and standardizing data formats to create a reliable foundation for the TreeKipedia database.

**Column Selection**: We are in the process of selecting the most relevant columns from each dataset, focusing on providing essential information for various user groups, such as observers, planters, and data validators.

**Data Integration:** Preparing the cleaned and selected data for integration into the TreeKipedia platform. This step is crucial for creating a cohesive and functional database that supports all user activities.



### Completed Steps

#### Step 1: Data Acquisition and Ingestion

**Data Source Selection:** Prioritize suitable data sources like GBIF, Wikidata, and other relevant repositories.&#x20;

**Data Extraction:** Develop web scraping techniques to extract the desired tree-related data from these sources.

<div><figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.12.14 PM.png" alt=""><figcaption></figcaption></figure> <figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.12.03 PM.png" alt=""><figcaption></figcaption></figure></div>

**Data Cleaning and Standardization:** Clean and standardize the extracted data to ensure consistency, accuracy, and compatibility.

**Data Ingestion:** Store the cleaned data in a suitable data storage system, such as GraphDB.



#### **Step 2: Ontology Development and Data Enrichment**

**Ontology Creation:** Develop a comprehensive ontology that defines the terms, concepts, and relationships relevant to tree data. This ontology provides a structured framework for organizing and understanding the information.

<div><figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.20.46 PM.png" alt=""><figcaption></figcaption></figure> <figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.20.59 PM.png" alt=""><figcaption></figcaption></figure> <figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.21.09 PM.png" alt=""><figcaption></figcaption></figure></div>

**Data Enrichment:** Use the ontology to annotate and enrich the ingested data with additional context and meaning. Adding taxonomic information, geographical coordinates, or other relevant details.



#### Step 3: Data Processing and Analysis

**Data Transformation:** Applying  transformations to the data, such as data cleaning, normalization, and feature engineering using R-Studio.

**Data Analysis:** Planning to use statistical methods, machine learning algorithms, or other analytical techniques to extract insights and patterns from the data. This might involve tasks like species identification, habitat analysis, or trend analysis.



### Additional Supporting images

Database filtering process:

<figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.23.34 PM.png" alt=""><figcaption></figcaption></figure>

Graph Database Setup:&#x20;

<div><figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.24.02 PM.png" alt=""><figcaption></figcaption></figure> <figure><img src="../.gitbook/assets/Screenshot 2024-09-24 at 4.24.11 PM.png" alt=""><figcaption></figcaption></figure></div>

